{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a55ef8e-4a6b-4cd3-a190-fde5713d32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from utils import evaluate_model, create_balanced_dataset, train_and_evaluate_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdee6cd-c808-4d4d-bc7e-e9c63140aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.read_csv(\"../../data/preprocessed/PSP_Jan_Feb_2019_preprocessed.csv\", sep=\";\").sample(frac=1).reset_index(drop=True)\n",
    "df_preprocessed_feature_selection = pd.read_csv(\"../../data/preprocessed/PSP_Jan_Feb_2019_preprocessed_general_feature_selection.csv\", sep=\";\").sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c4437d-9f5f-4425-b29b-32409bd2a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = create_balanced_dataset(df_preprocessed,42)\n",
    "df_balanced_feature_selection = create_balanced_dataset(df_preprocessed_feature_selection,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d78d3a6-c9fd-483f-938e-6e41ff1ec8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>success</th>\n",
       "      <th>3D_secured</th>\n",
       "      <th>previous_attempts</th>\n",
       "      <th>PSP_Moneycard</th>\n",
       "      <th>PSP_Simplecard</th>\n",
       "      <th>PSP_UK_Card</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Switzerland</th>\n",
       "      <th>card_Master</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>week_day_1</th>\n",
       "      <th>week_day_2</th>\n",
       "      <th>week_day_3</th>\n",
       "      <th>week_day_4</th>\n",
       "      <th>week_day_5</th>\n",
       "      <th>week_day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25614</th>\n",
       "      <td>0.320513</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21755</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25893</th>\n",
       "      <td>0.323718</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36285</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15452</th>\n",
       "      <td>0.169872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50308</th>\n",
       "      <td>0.738782</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50309</th>\n",
       "      <td>0.743590</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50311</th>\n",
       "      <td>0.748397</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50318</th>\n",
       "      <td>0.759615</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50321</th>\n",
       "      <td>0.786859</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20456 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount  success  3D_secured  previous_attempts  PSP_Moneycard  \\\n",
       "25614  0.320513    False       False                  2          False   \n",
       "21755  0.269231    False       False                  0          False   \n",
       "25893  0.323718    False        True                  1           True   \n",
       "36285  0.500000    False       False                  0          False   \n",
       "15452  0.169872    False       False                  2          False   \n",
       "...         ...      ...         ...                ...            ...   \n",
       "50308  0.738782     True       False                  0           True   \n",
       "50309  0.743590     True       False                  0          False   \n",
       "50311  0.748397     True       False                  0           True   \n",
       "50318  0.759615     True       False                  0          False   \n",
       "50321  0.786859     True        True                  1           True   \n",
       "\n",
       "       PSP_Simplecard  PSP_UK_Card  country_Germany  country_Switzerland  \\\n",
       "25614            True        False             True                False   \n",
       "21755            True        False             True                False   \n",
       "25893           False        False             True                False   \n",
       "36285           False         True             True                False   \n",
       "15452           False         True             True                False   \n",
       "...               ...          ...              ...                  ...   \n",
       "50308           False        False            False                 True   \n",
       "50309           False        False            False                 True   \n",
       "50311           False        False            False                 True   \n",
       "50318           False         True            False                 True   \n",
       "50321           False        False            False                 True   \n",
       "\n",
       "       card_Master  ...  hour_20  hour_21  hour_22  hour_23  week_day_1  \\\n",
       "25614         True  ...    False    False    False    False       False   \n",
       "21755        False  ...     True    False    False    False       False   \n",
       "25893         True  ...    False    False    False    False        True   \n",
       "36285         True  ...     True    False    False    False       False   \n",
       "15452         True  ...    False    False    False    False       False   \n",
       "...            ...  ...      ...      ...      ...      ...         ...   \n",
       "50308         True  ...    False    False    False    False       False   \n",
       "50309         True  ...    False    False    False    False       False   \n",
       "50311         True  ...    False    False    False    False       False   \n",
       "50318        False  ...    False     True    False    False       False   \n",
       "50321         True  ...    False     True    False    False       False   \n",
       "\n",
       "       week_day_2  week_day_3  week_day_4  week_day_5  week_day_6  \n",
       "25614        True       False       False       False       False  \n",
       "21755       False        True       False       False       False  \n",
       "25893       False       False       False       False       False  \n",
       "36285       False        True       False       False       False  \n",
       "15452       False       False       False       False       False  \n",
       "...           ...         ...         ...         ...         ...  \n",
       "50308       False       False       False        True       False  \n",
       "50309       False       False        True       False       False  \n",
       "50311       False        True       False       False       False  \n",
       "50318       False       False       False        True       False  \n",
       "50321       False       False       False       False        True  \n",
       "\n",
       "[20456 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b10071-88e9-4d99-acf6-ac69fb27ff4a",
   "metadata": {},
   "source": [
    "## Modell Auswahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc0b3326-b0c0-4a56-8b64-a42ae3446130",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c624d4-bcfd-4919-b15a-2879202b2be8",
   "metadata": {},
   "source": [
    "## Ganzer Datensatz Kreuzvalidierung, um Basismodelle zu bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09fc3c5c-9ecc-4d23-bfb8-d65aeeb8f49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Decision Tree:\n",
      "Accuracy: 0.5505958887890903\n",
      "Precision: 0.5578452558004883\n",
      "Recall: 0.4876792692282873\n",
      "F1 Score: 0.5203732885747183\n",
      "--------------------------------------\n",
      "Evaluation results for Random Forest:\n",
      "Accuracy: 0.5621819515121886\n",
      "Precision: 0.5629853590447338\n",
      "Recall: 0.555826695060073\n",
      "F1 Score: 0.5593009695525837\n",
      "--------------------------------------\n",
      "Evaluation results for Logistic Regression:\n",
      "Accuracy: 0.5828116603382529\n",
      "Precision: 0.5930565583340479\n",
      "Recall: 0.528353493129895\n",
      "F1 Score: 0.5587995756727219\n",
      "--------------------------------------\n",
      "Evaluation results for Gradient Boosting:\n",
      "Accuracy: 0.6205510367392075\n",
      "Precision: 0.6147694205809533\n",
      "Recall: 0.6465595460879\n",
      "F1 Score: 0.6301358908011465\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = df_balanced_feature_selection.copy()\n",
    "y = X.pop(\"success\")\n",
    "\n",
    "results = train_and_evaluate_classifiers(classifiers, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8f5f9ac-441b-4a7c-b3b5-2563c55a953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Decision Tree:\n",
      "Accuracy: 0.5507433048680161\n",
      "Precision: 0.5518547033156556\n",
      "Recall: 0.5401839357372128\n",
      "F1 Score: 0.5459507008843281\n",
      "--------------------------------------\n",
      "Evaluation results for Random Forest:\n",
      "Accuracy: 0.5881401918667041\n",
      "Precision: 0.5900653799046653\n",
      "Recall: 0.5775303472456245\n",
      "F1 Score: 0.5836701540142875\n",
      "--------------------------------------\n",
      "Evaluation results for Logistic Regression:\n",
      "Accuracy: 0.5797812736777892\n",
      "Precision: 0.588339352620727\n",
      "Recall: 0.5311889619437533\n",
      "F1 Score: 0.5582618108846483\n",
      "--------------------------------------\n",
      "Evaluation results for Gradient Boosting:\n",
      "Accuracy: 0.6192314722755266\n",
      "Precision: 0.6064755863850114\n",
      "Recall: 0.6791138771578868\n",
      "F1 Score: 0.6407097397845141\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = df_balanced.copy()\n",
    "y = X.pop(\"success\")\n",
    "\n",
    "results = train_and_evaluate_classifiers(classifiers, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4035e4-e207-4a22-b7c0-099fc4cffce9",
   "metadata": {},
   "source": [
    "#### Frage: macht man das wirklich mit dem ganzen Datensatz? -> Ja das beurteilt ja nur die Performance\n",
    "#### Warum ist der Unterschied so groß? -> Durch den concat Schritt bekommt CV ein Problem, da nur ähnliche Werte ausgewählt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790000a-d24d-4f06-9ff1-75ae50d096cb",
   "metadata": {},
   "source": [
    "## Professionelles Over/Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc00841-590c-49bd-9b1f-7cdd925e33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8afb5d84-4af2-49f4-84f5-f6f43d63c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampling_datasets(df, samplers):\n",
    "    X = df\n",
    "    y = X.pop(\"success\")\n",
    "    data = {}\n",
    "    for i_sampler in samplers.keys():\n",
    "        df_resampled, y_resampled = samplers[i_sampler].fit_resample(X, y)\n",
    "        data[i_sampler] = (df_resampled, y_resampled)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca2e7ac6-5128-4419-b9b1-828576dbec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv_with_sampling(df, classifiers, samplers):\n",
    "    X = df\n",
    "    y = X.pop(\"success\")\n",
    "    res_list = []\n",
    "    for i_sampler in samplers.keys():\n",
    "        df_resampled, y_resampled = samplers[i_sampler].fit_resample(X, y)\n",
    "        results = train_and_evaluate_classifiers(classifiers, df_resampled, y_resampled)\n",
    "        for res in results:\n",
    "            res[\"sampler\"] = i_sampler\n",
    "            res_list.append(res)\n",
    "        \n",
    "    return pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f131b1c6-3996-4217-9b20-2dfc1af88e4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Decision Tree:\n",
      "Accuracy: 0.5587112401086427\n",
      "Precision: 0.5586944137890008\n",
      "Recall: 0.5590539355221112\n",
      "F1 Score: 0.5588651138824069\n",
      "--------------------------------------\n",
      "Evaluation results for Random Forest:\n",
      "Accuracy: 0.5945443267330022\n",
      "Precision: 0.5964633399896353\n",
      "Recall: 0.5854524422392551\n",
      "F1 Score: 0.5908481612628438\n",
      "--------------------------------------\n",
      "Evaluation results for Logistic Regression:\n",
      "Accuracy: 0.5825185007836147\n",
      "Precision: 0.5919518618058455\n",
      "Recall: 0.5311911607597387\n",
      "F1 Score: 0.5598499019297544\n",
      "--------------------------------------\n",
      "Evaluation results for Gradient Boosting:\n",
      "Accuracy: 0.6199651118864026\n",
      "Precision: 0.6102249679012777\n",
      "Recall: 0.6644530803738943\n",
      "F1 Score: 0.6361077361558738\n",
      "--------------------------------------\n",
      "Evaluation results for Decision Tree:\n",
      "Accuracy: 0.5516723403757096\n",
      "Precision: 0.5525046150374988\n",
      "Recall: 0.5428238533294137\n",
      "F1 Score: 0.5475202478029535\n",
      "--------------------------------------\n",
      "Evaluation results for Random Forest:\n",
      "Accuracy: 0.5973305372186473\n",
      "Precision: 0.5999691438597002\n",
      "Recall: 0.5848661231767156\n",
      "F1 Score: 0.5922630705696631\n",
      "--------------------------------------\n",
      "Evaluation results for Logistic Regression:\n",
      "Accuracy: 0.5829093164715815\n",
      "Precision: 0.5925980110345883\n",
      "Recall: 0.5307991023094738\n",
      "F1 Score: 0.559963749390351\n",
      "--------------------------------------\n",
      "Evaluation results for Gradient Boosting:\n",
      "Accuracy: 0.6247558656402618\n",
      "Precision: 0.6149664401694968\n",
      "Recall: 0.6674829532010698\n",
      "F1 Score: 0.6401087706312885\n",
      "--------------------------------------\n",
      "Evaluation results for Decision Tree:\n",
      "Accuracy: 0.5999776448352786\n",
      "Precision: 0.5306476956753201\n",
      "Recall: 0.5211192385729337\n",
      "F1 Score: 0.52566540129366\n",
      "--------------------------------------\n",
      "Evaluation results for Random Forest:\n",
      "Accuracy: 0.6815325830075507\n",
      "Precision: 0.6472981309494872\n",
      "Recall: 0.5531942666562171\n",
      "F1 Score: 0.5964802291192568\n",
      "--------------------------------------\n",
      "Evaluation results for Logistic Regression:\n",
      "Accuracy: 0.6248037257556109\n",
      "Precision: 0.6105906062427922\n",
      "Recall: 0.32655868753102224\n",
      "F1 Score: 0.4254778029381347\n",
      "--------------------------------------\n",
      "Evaluation results for Gradient Boosting:\n",
      "Accuracy: 0.6406430304579259\n",
      "Precision: 0.6069611636789654\n",
      "Recall: 0.440999677804192\n",
      "F1 Score: 0.5107545112453656\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "samplers = {\"RUS\": RandomUnderSampler(), \"ROS\": RandomOverSampler(), \"ToL\": TomekLinks()}\n",
    "res = perform_cv_with_sampling(df_balanced.copy(), classifiers, samplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43f34a92-db59-411e-84e6-68d9f4bde23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>sampler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.558711</td>\n",
       "      <td>0.558694</td>\n",
       "      <td>0.559054</td>\n",
       "      <td>0.558865</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>0.552505</td>\n",
       "      <td>0.542824</td>\n",
       "      <td>0.547520</td>\n",
       "      <td>ROS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.599978</td>\n",
       "      <td>0.530648</td>\n",
       "      <td>0.521119</td>\n",
       "      <td>0.525665</td>\n",
       "      <td>ToL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.619965</td>\n",
       "      <td>0.610225</td>\n",
       "      <td>0.664453</td>\n",
       "      <td>0.636108</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>0.614966</td>\n",
       "      <td>0.667483</td>\n",
       "      <td>0.640109</td>\n",
       "      <td>ROS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.640643</td>\n",
       "      <td>0.606961</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.510755</td>\n",
       "      <td>ToL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.582519</td>\n",
       "      <td>0.591952</td>\n",
       "      <td>0.531191</td>\n",
       "      <td>0.559850</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>0.592598</td>\n",
       "      <td>0.530799</td>\n",
       "      <td>0.559964</td>\n",
       "      <td>ROS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.624804</td>\n",
       "      <td>0.610591</td>\n",
       "      <td>0.326559</td>\n",
       "      <td>0.425478</td>\n",
       "      <td>ToL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.594544</td>\n",
       "      <td>0.596463</td>\n",
       "      <td>0.585452</td>\n",
       "      <td>0.590848</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.599969</td>\n",
       "      <td>0.584866</td>\n",
       "      <td>0.592263</td>\n",
       "      <td>ROS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.681533</td>\n",
       "      <td>0.647298</td>\n",
       "      <td>0.553194</td>\n",
       "      <td>0.596480</td>\n",
       "      <td>ToL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             classifier  accuracy  precision    recall        f1 sampler\n",
       "0         Decision Tree  0.558711   0.558694  0.559054  0.558865     RUS\n",
       "4         Decision Tree  0.551672   0.552505  0.542824  0.547520     ROS\n",
       "8         Decision Tree  0.599978   0.530648  0.521119  0.525665     ToL\n",
       "3     Gradient Boosting  0.619965   0.610225  0.664453  0.636108     RUS\n",
       "7     Gradient Boosting  0.624756   0.614966  0.667483  0.640109     ROS\n",
       "11    Gradient Boosting  0.640643   0.606961  0.441000  0.510755     ToL\n",
       "2   Logistic Regression  0.582519   0.591952  0.531191  0.559850     RUS\n",
       "6   Logistic Regression  0.582909   0.592598  0.530799  0.559964     ROS\n",
       "10  Logistic Regression  0.624804   0.610591  0.326559  0.425478     ToL\n",
       "1         Random Forest  0.594544   0.596463  0.585452  0.590848     RUS\n",
       "5         Random Forest  0.597331   0.599969  0.584866  0.592263     ROS\n",
       "9         Random Forest  0.681533   0.647298  0.553194  0.596480     ToL"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(\"classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d27ce-4f01-4b62-a400-1929278fe1ab",
   "metadata": {},
   "source": [
    "#### Erkenntnisse:\n",
    " - ToL erhöht die Genauigkeit bei einer Reduzierung von den anderen Metriken\n",
    " - RUS und ROS erzielen ähnliche Ergebnisse, Performancegewinn ist abhängig vom Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7716425-48e7-4df1-b9e9-d1cb7f8a099b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30e549c1-cf97-4c3d-8d14-f873ec354ac8",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad63087d-a242-4cd9-9884-1c3fbcd75c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d494ec91-dd7e-4df7-9d0d-a95f70b58773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "data = create_sampling_datasets(df_balanced, samplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6379c570-68ba-4e8e-934f-982650c302c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "17799     True\n",
       "17800     True\n",
       "17801     True\n",
       "17802     True\n",
       "17803     True\n",
       "Name: success, Length: 17804, dtype: bool"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ToL\"][1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c35de-e56b-473f-b430-4f2743be52ac",
   "metadata": {},
   "source": [
    "#### Logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77cc67eb-bc83-4c46-85ca-6c4d205ef44b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_accuracy',\n",
       " 'mean_test_f1',\n",
       " 'mean_test_precision',\n",
       " 'mean_test_recall',\n",
       " 'param_solver',\n",
       " 'params',\n",
       " 'rank_test_accuracy',\n",
       " 'rank_test_f1',\n",
       " 'rank_test_precision',\n",
       " 'rank_test_recall',\n",
       " 'split0_test_accuracy',\n",
       " 'split0_test_f1',\n",
       " 'split0_test_precision',\n",
       " 'split0_test_recall',\n",
       " 'split1_test_accuracy',\n",
       " 'split1_test_f1',\n",
       " 'split1_test_precision',\n",
       " 'split1_test_recall',\n",
       " 'split2_test_accuracy',\n",
       " 'split2_test_f1',\n",
       " 'split2_test_precision',\n",
       " 'split2_test_recall',\n",
       " 'split3_test_accuracy',\n",
       " 'split3_test_f1',\n",
       " 'split3_test_precision',\n",
       " 'split3_test_recall',\n",
       " 'split4_test_accuracy',\n",
       " 'split4_test_f1',\n",
       " 'split4_test_precision',\n",
       " 'split4_test_recall',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_accuracy',\n",
       " 'std_test_f1',\n",
       " 'std_test_precision',\n",
       " 'std_test_recall']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'solver':('lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky')}\n",
    "clf = LogisticRegression(max_iter = 10000, penalty = \"l2\")\n",
    "clf = GridSearchCV(clf, parameters, refit = \"f1\", scoring=[\"f1\",\"precision\",\"recall\",\"accuracy\"], cv = 5)\n",
    "clf.fit(data[\"RUS\"][0], data[\"RUS\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d108a0f7-a7c6-4527-b2ed-7be6d7edc785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5581839609160666"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c47cd7a7-76d6-423f-b52c-30fc3bcfd8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;),\n",
       "             param_grid={&#x27;solver&#x27;: (&#x27;liblinear&#x27;, &#x27;saga&#x27;)}, refit=&#x27;f1&#x27;,\n",
       "             scoring=[&#x27;f1&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;),\n",
       "             param_grid={&#x27;solver&#x27;: (&#x27;liblinear&#x27;, &#x27;saga&#x27;)}, refit=&#x27;f1&#x27;,\n",
       "             scoring=[&#x27;f1&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=10000, penalty='l1'),\n",
       "             param_grid={'solver': ('liblinear', 'saga')}, refit='f1',\n",
       "             scoring=['f1', 'precision', 'recall', 'accuracy'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'solver':('liblinear', 'saga')}\n",
    "clf = LogisticRegression(max_iter = 10000, penalty = \"l1\")\n",
    "clf = GridSearchCV(clf, parameters, refit = \"f1\", scoring=[\"f1\",\"precision\",\"recall\",\"accuracy\"], cv = 5)\n",
    "clf.fit(data[\"RUS\"][0], data[\"RUS\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eac1bc64-734e-4647-a48c-8e2de332733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558753853241555"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86949863-cd72-4be9-8dd1-4e3135c500d5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4f5e9fe-bba7-41da-9e33-cc67b60baed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: (&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;),\n",
       "                         &#x27;max_depth&#x27;: (3, 5, 7, 9, 11),\n",
       "                         &#x27;min_samples_split&#x27;: (2, 4, 6, 8),\n",
       "                         &#x27;n_estimators&#x27;: (25, 100, 150, 200)},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;f1&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: (&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;),\n",
       "                         &#x27;max_depth&#x27;: (3, 5, 7, 9, 11),\n",
       "                         &#x27;min_samples_split&#x27;: (2, 4, 6, 8),\n",
       "                         &#x27;n_estimators&#x27;: (25, 100, 150, 200)},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;f1&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ('gini', 'entropy', 'log_loss'),\n",
       "                         'max_depth': (3, 5, 7, 9, 11),\n",
       "                         'min_samples_split': (2, 4, 6, 8),\n",
       "                         'n_estimators': (25, 100, 150, 200)},\n",
       "             refit='f1', scoring=['f1', 'precision', 'recall', 'accuracy'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'n_estimators':(25, 100, 150, 200), \n",
    "              'criterion':('gini','entropy','log_loss'), \n",
    "              'max_depth':(3,5,7,9,11), \n",
    "              'min_samples_split':(2,4,6,8)\n",
    "             }\n",
    "clf = RandomForestClassifier()\n",
    "clf = GridSearchCV(clf, parameters, refit = \"f1\", scoring=[\"f1\",\"precision\",\"recall\",\"accuracy\"], cv = 5)\n",
    "clf.fit(data[\"RUS\"][0], data[\"RUS\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774b1a8-ab45-49ca-976d-2bc667d7fbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a76e3389-55b5-49e8-b93a-79dd8a347d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=11, min_samples_split=4,\n",
       "                       n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=11, min_samples_split=4,\n",
       "                       n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_depth=11, min_samples_split=4,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "635b7b71-852d-4fac-a296-4d4601634b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6516990660670758"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcdc7f2-e7d2-4593-bfb9-1b5220f9bc3d",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5625e8c-22af-4757-9836-6e74c6b4a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: (&#x27;friedman_mse&#x27;, &#x27;squared_error&#x27;),\n",
       "                         &#x27;max_depth&#x27;: (3, 7, 11, 15),\n",
       "                         &#x27;min_samples_leaf&#x27;: (2, 4, 8),\n",
       "                         &#x27;min_samples_split&#x27;: (2, 4, 8),\n",
       "                         &#x27;n_estimators&#x27;: (25, 100, 200)},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;f1&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: (&#x27;friedman_mse&#x27;, &#x27;squared_error&#x27;),\n",
       "                         &#x27;max_depth&#x27;: (3, 7, 11, 15),\n",
       "                         &#x27;min_samples_leaf&#x27;: (2, 4, 8),\n",
       "                         &#x27;min_samples_split&#x27;: (2, 4, 8),\n",
       "                         &#x27;n_estimators&#x27;: (25, 100, 200)},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;f1&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'criterion': ('friedman_mse', 'squared_error'),\n",
       "                         'max_depth': (3, 7, 11, 15),\n",
       "                         'min_samples_leaf': (2, 4, 8),\n",
       "                         'min_samples_split': (2, 4, 8),\n",
       "                         'n_estimators': (25, 100, 200)},\n",
       "             refit='f1', scoring=['f1', 'precision', 'recall', 'accuracy'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'n_estimators':(25, 100, 200), \n",
    "              'criterion':('friedman_mse','squared_error'), \n",
    "              'max_depth':(3,7,11,15), \n",
    "              'min_samples_split':(2,4,8),\n",
    "              'min_samples_leaf':(2,4,8)\n",
    "             }\n",
    "clf_GB = GradientBoostingClassifier()\n",
    "clf_GB = GridSearchCV(clf_GB, parameters, refit = \"f1\", scoring=[\"f1\",\"precision\",\"recall\",\"accuracy\"], cv = 5)\n",
    "clf_GB.fit(data[\"RUS\"][0], data[\"RUS\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc429763-dff6-43b0-878b-d6f6e79050be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(min_samples_leaf=8, n_estimators=25)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(min_samples_leaf=8, n_estimators=25)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(min_samples_leaf=8, n_estimators=25)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GB.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cdc8ee1b-0378-42c5-b736-8bb56b1a3da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.27401934,  1.07083707,  2.14350314,  0.28793955,  1.07682567,\n",
       "         2.11454144,  0.2793644 ,  1.06119485,  2.11113868,  0.2769968 ,\n",
       "         1.05989842,  2.12201056,  0.27722063,  1.06871715,  2.10847669,\n",
       "         0.27287216,  1.07666049,  2.11038356,  0.27432046,  1.06776199,\n",
       "         2.12374797,  0.27505927,  1.05814199,  2.09387436,  0.27501044,\n",
       "         1.0558146 ,  2.10952144,  0.64178333,  2.46748481,  4.85532522,\n",
       "         0.63632569,  2.44744854,  4.88863344,  0.63473878,  2.43478279,\n",
       "         4.81550574,  0.63171635,  2.47242923,  4.97396417,  0.64176202,\n",
       "         2.46393008,  4.83543181,  0.65147777,  2.42867489,  4.81498995,\n",
       "         0.64131866,  2.40269222,  4.73039145,  0.6441256 ,  2.42750239,\n",
       "         4.73497229,  0.62735071,  2.42695165,  4.76058331,  1.22896743,\n",
       "         4.4463973 ,  8.77156057,  1.21886024,  4.4306406 ,  8.82508259,\n",
       "         1.13803277,  4.13695364,  8.30886836,  1.16738896,  4.1175961 ,\n",
       "         8.0883451 ,  1.13171792,  4.1108098 ,  8.08638849,  1.13210602,\n",
       "         4.10790935,  8.09930673,  1.04825068,  3.8366673 ,  7.59708123,\n",
       "         1.06949573,  3.92075772,  7.67899857,  1.06369991,  3.86408224,\n",
       "         7.55049806,  2.0416563 ,  7.2847806 , 14.13463964,  2.04972215,\n",
       "         7.23610573, 14.25213852,  1.74633336,  6.27676163, 12.40492797,\n",
       "         1.69639182,  6.08868985, 11.98370442,  1.71446323,  6.06767292,\n",
       "        11.91302848,  1.68137212,  6.06372104, 11.91318164,  1.43820806,\n",
       "         5.27591491, 10.41536903,  1.43110294,  5.30883355, 10.5141789 ,\n",
       "         1.43033214,  5.28928161, 10.50005126,  0.27428551,  1.06967254,\n",
       "         2.14035206,  0.28877711,  1.08142262,  2.11730528,  0.27841115,\n",
       "         1.08740931,  2.12042551,  0.27974644,  1.07493024,  2.09615359,\n",
       "         0.27417207,  1.05966978,  2.10669413,  0.27678914,  1.06517649,\n",
       "         2.11624641,  0.27637377,  1.07763381,  2.13140278,  0.2765244 ,\n",
       "         1.06722565,  2.1175653 ,  0.27796435,  1.06037254,  2.11286235,\n",
       "         0.64381213,  2.48687201,  4.82682366,  0.63641167,  2.43324318,\n",
       "         4.83140469,  0.62713146,  2.40971522,  4.76087618,  0.62822609,\n",
       "         2.40323229,  4.75978184,  0.62890096,  2.40826364,  4.76479235,\n",
       "         0.62709875,  2.40574079,  4.76545529,  0.62273431,  2.37658644,\n",
       "         4.68483157,  0.62171144,  2.36918912,  4.68523245,  0.62602205,\n",
       "         2.38529572,  4.71444273,  1.21645484,  4.39639325,  8.67506466,\n",
       "         1.21575594,  4.42473779,  8.66699777,  1.13433013,  4.11747336,\n",
       "         8.12044778,  1.12118721,  4.07911024,  8.02018099,  1.12118106,\n",
       "         4.07751131,  8.03132715,  1.12600031,  4.06748562,  8.02506757,\n",
       "         1.04108977,  3.82000413,  7.50487719,  1.04316921,  3.80885816,\n",
       "         7.52122135,  1.04205217,  3.81447902,  7.51956558,  2.03357859,\n",
       "         7.20804739, 14.0215601 ,  2.03572102,  7.19999847, 14.01902466,\n",
       "         1.74086633,  6.24289298, 12.2012805 ,  1.6827126 ,  6.02182798,\n",
       "        11.82069778,  1.68276291,  5.99289269, 11.80786839,  1.68279967,\n",
       "         6.00988379, 11.78901596,  1.42074103,  5.24258857, 10.35938334,\n",
       "         1.42186227,  5.22575946, 10.33072233,  1.42198339,  5.23031764,\n",
       "        10.3544075 ]),\n",
       " 'std_fit_time': array([0.00135923, 0.01624227, 0.03085109, 0.00657306, 0.01425284,\n",
       "        0.01155757, 0.00302085, 0.00411857, 0.0068499 , 0.00355813,\n",
       "        0.00320498, 0.02251235, 0.00536094, 0.0131234 , 0.0058507 ,\n",
       "        0.00071179, 0.01387889, 0.0182974 , 0.00052993, 0.00905522,\n",
       "        0.01692837, 0.0021306 , 0.0033209 , 0.00404059, 0.00260587,\n",
       "        0.00175122, 0.01465125, 0.00606186, 0.0172721 , 0.02192226,\n",
       "        0.00348652, 0.01629604, 0.02389731, 0.00269619, 0.00832934,\n",
       "        0.01901998, 0.00174215, 0.09566611, 0.12378412, 0.00707176,\n",
       "        0.03421274, 0.02207507, 0.01725494, 0.03404127, 0.02579877,\n",
       "        0.00899634, 0.01026641, 0.01600566, 0.01771574, 0.0463094 ,\n",
       "        0.02113895, 0.00336011, 0.01668627, 0.03311938, 0.01094697,\n",
       "        0.0257781 , 0.07591731, 0.00410515, 0.02816773, 0.08247115,\n",
       "        0.00425026, 0.01716808, 0.0603762 , 0.06078437, 0.01959787,\n",
       "        0.0296507 , 0.00469275, 0.02421426, 0.02701677, 0.00145546,\n",
       "        0.02111359, 0.03019978, 0.00449322, 0.0071478 , 0.0446224 ,\n",
       "        0.01859935, 0.06589893, 0.08052862, 0.00471258, 0.01100504,\n",
       "        0.03396132, 0.00885549, 0.01912115, 0.11695139, 0.00852842,\n",
       "        0.05093936, 0.10239014, 0.00549148, 0.01494472, 0.06189043,\n",
       "        0.01093738, 0.03335027, 0.06229911, 0.02278932, 0.04301901,\n",
       "        0.06577084, 0.01471552, 0.01705535, 0.05958598, 0.0050571 ,\n",
       "        0.01405891, 0.04858698, 0.00733951, 0.02073322, 0.08345101,\n",
       "        0.00289761, 0.02990823, 0.04977845, 0.00188386, 0.01334876,\n",
       "        0.01864455, 0.00477048, 0.00895159, 0.01482773, 0.00158751,\n",
       "        0.01341508, 0.01426222, 0.0048782 , 0.00386579, 0.00304246,\n",
       "        0.00151646, 0.00629533, 0.00714737, 0.00551211, 0.01023949,\n",
       "        0.01165383, 0.00329939, 0.0033509 , 0.00805184, 0.00227454,\n",
       "        0.00626098, 0.01106738, 0.00564355, 0.00717053, 0.00848695,\n",
       "        0.00685401, 0.08188113, 0.0087769 , 0.00240658, 0.00743331,\n",
       "        0.0384189 , 0.00135188, 0.00215748, 0.01379687, 0.00273165,\n",
       "        0.00455871, 0.00793941, 0.00101705, 0.0085187 , 0.01626344,\n",
       "        0.00130457, 0.00856052, 0.01097578, 0.00275331, 0.00530171,\n",
       "        0.01164711, 0.00175086, 0.0039164 , 0.00807896, 0.00534413,\n",
       "        0.01348421, 0.03736377, 0.0064486 , 0.01773997, 0.03840272,\n",
       "        0.00323983, 0.01742505, 0.03943103, 0.00368685, 0.0218906 ,\n",
       "        0.03258938, 0.00276768, 0.01147511, 0.01329125, 0.00161516,\n",
       "        0.01162649, 0.02882558, 0.00422988, 0.01842128, 0.01247422,\n",
       "        0.00103365, 0.00664993, 0.01851427, 0.00177955, 0.01635708,\n",
       "        0.02073613, 0.00445484, 0.00529624, 0.02233629, 0.00673373,\n",
       "        0.03768481, 0.05586143, 0.00774206, 0.05990037, 0.02613442,\n",
       "        0.01136983, 0.03074799, 0.0343187 , 0.00807583, 0.03524156,\n",
       "        0.02459761, 0.01054894, 0.04106384, 0.03016173, 0.00730537,\n",
       "        0.0530165 , 0.028763  , 0.00342151, 0.00500605, 0.01991387,\n",
       "        0.0040406 , 0.02020475, 0.02052369, 0.00393299, 0.01868573,\n",
       "        0.02770552]),\n",
       " 'mean_score_time': array([0.00919476, 0.0117331 , 0.01509476, 0.00948176, 0.01175241,\n",
       "        0.01481495, 0.00901718, 0.01172414, 0.0149951 , 0.01017475,\n",
       "        0.01161108, 0.0151165 , 0.00908899, 0.01151037, 0.01486673,\n",
       "        0.00890555, 0.01181979, 0.01470189, 0.0088366 , 0.01134934,\n",
       "        0.01482167, 0.00884624, 0.01171122, 0.01481414, 0.00878553,\n",
       "        0.01171312, 0.01524873, 0.01045136, 0.01611333, 0.02260756,\n",
       "        0.01056213, 0.01612849, 0.02312932, 0.01071067, 0.01654677,\n",
       "        0.02319012, 0.01030965, 0.01631498, 0.02371955, 0.01050801,\n",
       "        0.01634521, 0.02361646, 0.01052213, 0.01627235, 0.02278261,\n",
       "        0.01057119, 0.01528325, 0.02213984, 0.01042919, 0.01541367,\n",
       "        0.02223883, 0.01020889, 0.01577115, 0.02241321, 0.01247702,\n",
       "        0.0236805 , 0.03678689, 0.01320982, 0.02312255, 0.03738246,\n",
       "        0.01235204, 0.0221859 , 0.03628345, 0.01273122, 0.02317657,\n",
       "        0.03486013, 0.0125586 , 0.02180438, 0.03531933, 0.01261086,\n",
       "        0.02193365, 0.03438568, 0.01237593, 0.02101169, 0.03208184,\n",
       "        0.01254849, 0.02090125, 0.03320146, 0.01257706, 0.02161403,\n",
       "        0.0324441 , 0.0153677 , 0.03334274, 0.05549145, 0.01555877,\n",
       "        0.03248153, 0.05616784, 0.0146874 , 0.03023086, 0.05151167,\n",
       "        0.0142118 , 0.03043242, 0.0505559 , 0.01464405, 0.02983131,\n",
       "        0.0498343 , 0.01460695, 0.0297544 , 0.05066061, 0.01411085,\n",
       "        0.02700171, 0.04446735, 0.0137538 , 0.02767167, 0.04488096,\n",
       "        0.01394215, 0.02707815, 0.0445303 , 0.00910645, 0.0120729 ,\n",
       "        0.01555328, 0.0090836 , 0.0117393 , 0.01521435, 0.00985079,\n",
       "        0.01181617, 0.01521149, 0.00890088, 0.0115098 , 0.01478314,\n",
       "        0.00901012, 0.01191216, 0.0147398 , 0.00908508, 0.01201105,\n",
       "        0.0152133 , 0.00907722, 0.01181617, 0.01546307, 0.00898333,\n",
       "        0.01153984, 0.0147109 , 0.00930462, 0.01168962, 0.01474919,\n",
       "        0.01070867, 0.01581554, 0.02296739, 0.01070118, 0.01580186,\n",
       "        0.02237234, 0.01030169, 0.01640573, 0.02270346, 0.01030207,\n",
       "        0.01588159, 0.02180095, 0.01040082, 0.01609511, 0.02260065,\n",
       "        0.0100008 , 0.01610222, 0.02264986, 0.01040173, 0.01540489,\n",
       "        0.02200971, 0.01030164, 0.01590719, 0.02190838, 0.01020045,\n",
       "        0.01540689, 0.0220047 , 0.01240168, 0.02300229, 0.0369225 ,\n",
       "        0.01219954, 0.02271385, 0.03710394, 0.01200089, 0.02193995,\n",
       "        0.03530741, 0.01220288, 0.02220783, 0.03451638, 0.01280193,\n",
       "        0.02160597, 0.0351017 , 0.01245847, 0.02220392, 0.035045  ,\n",
       "        0.01232138, 0.02110457, 0.03170319, 0.01210628, 0.02040229,\n",
       "        0.03230276, 0.01170111, 0.02060289, 0.03200111, 0.01520109,\n",
       "        0.03240762, 0.05441599, 0.0154007 , 0.03249536, 0.0545229 ,\n",
       "        0.01439996, 0.03060317, 0.05071011, 0.01411581, 0.02970366,\n",
       "        0.05024257, 0.01420012, 0.02970104, 0.0501586 , 0.01420522,\n",
       "        0.02988091, 0.04949822, 0.01380172, 0.02710223, 0.04470234,\n",
       "        0.01380439, 0.02670498, 0.04410782, 0.01350417, 0.02640476,\n",
       "        0.04470811]),\n",
       " 'std_score_time': array([5.45401093e-04, 4.48442225e-04, 3.54599881e-04, 3.80892752e-04,\n",
       "        4.46590887e-04, 5.10049788e-04, 4.24280540e-04, 2.65383445e-04,\n",
       "        6.22992829e-04, 1.28328862e-03, 4.90223493e-04, 5.86771972e-04,\n",
       "        5.63306910e-04, 6.32410393e-04, 1.92499675e-04, 4.92830029e-04,\n",
       "        4.48838547e-04, 2.36639029e-04, 5.23789733e-04, 5.30587884e-04,\n",
       "        3.92129077e-04, 5.53228033e-04, 5.09537322e-04, 2.46746067e-04,\n",
       "        3.92283135e-04, 2.49104934e-04, 2.23267277e-04, 7.27542369e-04,\n",
       "        5.85628666e-04, 3.77029385e-04, 5.13593230e-04, 5.77891372e-04,\n",
       "        5.16573951e-04, 3.99380751e-04, 3.23019303e-04, 6.68114418e-04,\n",
       "        4.00638779e-04, 4.43596946e-04, 1.57973722e-03, 6.32259072e-04,\n",
       "        2.97827366e-04, 1.37714538e-03, 8.36294485e-04, 3.87408561e-04,\n",
       "        6.90822421e-04, 5.81436613e-04, 3.36654787e-04, 3.94279470e-04,\n",
       "        5.14667608e-04, 7.34354375e-04, 4.43673712e-04, 3.99688575e-04,\n",
       "        2.18090116e-04, 1.99229469e-04, 8.44570733e-04, 3.77875725e-04,\n",
       "        3.15052542e-04, 3.99533230e-04, 3.74178922e-04, 7.20673114e-04,\n",
       "        5.82789048e-04, 5.26413291e-04, 1.04620141e-03, 3.11686446e-04,\n",
       "        1.68844385e-03, 5.07101286e-04, 5.80025386e-04, 4.86525283e-04,\n",
       "        7.80530242e-04, 2.03992441e-04, 3.80040549e-04, 9.25467013e-04,\n",
       "        1.71495569e-04, 3.04435137e-04, 6.61424550e-04, 5.74200139e-04,\n",
       "        3.92929252e-04, 1.87554716e-03, 3.41030522e-04, 8.04208767e-04,\n",
       "        3.48092582e-04, 7.35523433e-04, 1.37695532e-03, 6.35617529e-04,\n",
       "        2.53907051e-04, 4.46722636e-04, 1.53910395e-03, 2.72170430e-04,\n",
       "        6.76577296e-04, 4.99066358e-04, 3.99890055e-04, 9.69374389e-04,\n",
       "        5.96720970e-04, 4.90645037e-04, 6.08893318e-04, 4.81762846e-04,\n",
       "        3.72387932e-04, 2.40678566e-04, 9.56068693e-04, 5.85560892e-04,\n",
       "        3.47943621e-04, 7.05481399e-04, 3.82339785e-04, 6.10248449e-04,\n",
       "        9.09774965e-04, 3.47499070e-04, 4.52491983e-04, 3.46346481e-04,\n",
       "        3.74538132e-04, 5.24840704e-04, 7.60144679e-04, 4.71023539e-04,\n",
       "        2.84823077e-04, 4.01891517e-04, 6.38592553e-04, 4.09333376e-04,\n",
       "        2.42472169e-04, 4.00877427e-04, 8.20381667e-07, 8.36116437e-04,\n",
       "        4.47456997e-04, 3.73556354e-04, 2.32153223e-04, 4.74522087e-04,\n",
       "        6.34488238e-04, 5.11203492e-04, 3.88269106e-04, 8.11945392e-04,\n",
       "        4.59577014e-04, 4.49139938e-04, 2.75533683e-04, 3.97604225e-04,\n",
       "        4.25124558e-04, 4.16612666e-04, 5.07448540e-04, 3.74121390e-04,\n",
       "        2.49514465e-04, 5.77098470e-04, 3.96502785e-04, 4.00763559e-04,\n",
       "        4.57975309e-04, 5.98941289e-04, 5.81851026e-04, 4.00120177e-04,\n",
       "        4.01443282e-04, 2.29088839e-04, 4.00522958e-04, 4.89845912e-04,\n",
       "        2.07114833e-04, 7.99597239e-04, 1.62824355e-06, 4.88649510e-04,\n",
       "        4.36177355e-04, 4.88134195e-04, 3.76718177e-04, 3.12068613e-04,\n",
       "        4.00344947e-04, 4.97592120e-04, 4.88737376e-04, 3.98185364e-04,\n",
       "        2.03514490e-04, 3.16233054e-04, 4.88540987e-04, 3.15931467e-04,\n",
       "        3.77036061e-04, 4.01190808e-04, 7.52230278e-04, 2.04067552e-04,\n",
       "        3.45369701e-06, 6.43557868e-04, 5.07774910e-04, 3.98460508e-04,\n",
       "        6.79552922e-04, 4.63652640e-04, 4.00934692e-04, 3.74144526e-04,\n",
       "        6.64013188e-04, 4.07031885e-04, 7.50112896e-04, 2.79725398e-04,\n",
       "        3.87907793e-04, 4.85861569e-04, 6.03127332e-04, 4.87981752e-04,\n",
       "        4.89028730e-04, 6.04324094e-04, 3.99246188e-04, 8.01003548e-04,\n",
       "        6.32943029e-04, 3.99947490e-04, 3.75288402e-04, 4.92438033e-04,\n",
       "        4.90627236e-04, 6.88285865e-04, 3.38262398e-04, 4.89823515e-04,\n",
       "        3.72286470e-04, 5.12403553e-04, 1.45582765e-04, 3.99181583e-04,\n",
       "        5.35399221e-04, 3.99399572e-04, 3.99946592e-04, 4.39397889e-04,\n",
       "        4.02450590e-04, 4.91657487e-04, 6.25470167e-04, 4.00379766e-04,\n",
       "        6.64598108e-04, 7.49724324e-04, 5.13346802e-04, 7.47875075e-04,\n",
       "        6.65094266e-04, 4.46081113e-04, 3.75397351e-04, 2.38494603e-04]),\n",
       " 'param_criterion': masked_array(data=['friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8,\n",
       "                    2, 2, 2, 4, 4, 4, 8, 8, 8, 2, 2, 2, 4, 4, 4, 8, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200,\n",
       "                    25, 100, 200, 25, 100, 200, 25, 100, 200, 25, 100, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 11,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 25},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'squared_error',\n",
       "   'max_depth': 15,\n",
       "   'min_samples_leaf': 8,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 200}],\n",
       " 'split0_test_f1': array([0.65150853, 0.64132463, 0.64367816, 0.65150853, 0.64132463,\n",
       "        0.64367816, 0.65150853, 0.64132463, 0.644044  , 0.65150853,\n",
       "        0.64372093, 0.64360832, 0.65150853, 0.64372093, 0.64360832,\n",
       "        0.65150853, 0.64372093, 0.64360832, 0.65136612, 0.6406141 ,\n",
       "        0.64175619, 0.65136612, 0.6406141 , 0.64175619, 0.65136612,\n",
       "        0.6406141 , 0.64175619, 0.65377532, 0.64073986, 0.61983471,\n",
       "        0.65349265, 0.6344697 , 0.61474811, 0.65302368, 0.63286295,\n",
       "        0.62566586, 0.65442021, 0.6407214 , 0.63096961, 0.6537931 ,\n",
       "        0.64085511, 0.62683691, 0.65442021, 0.63966086, 0.63096961,\n",
       "        0.65492797, 0.63951024, 0.62733813, 0.65492797, 0.64779429,\n",
       "        0.62310834, 0.65627864, 0.64779429, 0.62707382, 0.63676919,\n",
       "        0.5972873 , 0.59404467, 0.63595559, 0.59131293, 0.59360278,\n",
       "        0.63212435, 0.60044368, 0.59539718, 0.63947182, 0.6086096 ,\n",
       "        0.59483615, 0.63845792, 0.60814125, 0.58689176, 0.6433106 ,\n",
       "        0.60315116, 0.59538576, 0.63953216, 0.62012121, 0.6010929 ,\n",
       "        0.64300724, 0.61523438, 0.59290499, 0.63913656, 0.61628474,\n",
       "        0.60103118, 0.59942085, 0.59036743, 0.59272097, 0.60812772,\n",
       "        0.58937438, 0.58610422, 0.60793804, 0.5758483 , 0.58945805,\n",
       "        0.61368015, 0.59213147, 0.59428853, 0.60533981, 0.60138135,\n",
       "        0.59797381, 0.61408993, 0.5982187 , 0.59166875, 0.61963043,\n",
       "        0.5954311 , 0.59202378, 0.61812064, 0.59806115, 0.59338473,\n",
       "        0.61778097, 0.59595461, 0.59301461, 0.65150853, 0.64132463,\n",
       "        0.64367816, 0.65150853, 0.64132463, 0.64367816, 0.65150853,\n",
       "        0.64132463, 0.644044  , 0.65150853, 0.64372093, 0.64360832,\n",
       "        0.65150853, 0.64372093, 0.64360832, 0.65150853, 0.64372093,\n",
       "        0.64360832, 0.65136612, 0.6406141 , 0.64175619, 0.65136612,\n",
       "        0.6406141 , 0.64175619, 0.65136612, 0.6406141 , 0.64175619,\n",
       "        0.65103448, 0.63575844, 0.61882754, 0.65227377, 0.63343668,\n",
       "        0.61750484, 0.65302368, 0.63608418, 0.62068966, 0.6532872 ,\n",
       "        0.64085511, 0.63096961, 0.6532872 , 0.6407214 , 0.62721319,\n",
       "        0.65359779, 0.6407214 , 0.63096961, 0.65627864, 0.63951024,\n",
       "        0.62733813, 0.65492797, 0.64610313, 0.62310834, 0.65492797,\n",
       "        0.63951024, 0.62310834, 0.64217178, 0.60858896, 0.59405941,\n",
       "        0.63890849, 0.60650888, 0.58896313, 0.63368669, 0.60583763,\n",
       "        0.58706468, 0.64314279, 0.60736348, 0.59727385, 0.64243569,\n",
       "        0.61580113, 0.60093897, 0.63828786, 0.61300613, 0.59078456,\n",
       "        0.6402253 , 0.6175541 , 0.59807074, 0.63908368, 0.61823501,\n",
       "        0.59623949, 0.64095372, 0.61298194, 0.59768985, 0.60466246,\n",
       "        0.58768241, 0.58852744, 0.60582711, 0.59070687, 0.59443487,\n",
       "        0.60521236, 0.59336305, 0.58770839, 0.61594028, 0.5964738 ,\n",
       "        0.58668654, 0.61849711, 0.59885601, 0.59856896, 0.60850652,\n",
       "        0.5981216 , 0.5875    , 0.62556968, 0.59324957, 0.59004211,\n",
       "        0.61910462, 0.60078663, 0.59401496, 0.62239271, 0.6031746 ,\n",
       "        0.59694882]),\n",
       " 'split1_test_f1': array([0.64227273, 0.62392755, 0.62577271, 0.64227273, 0.62392755,\n",
       "        0.62577271, 0.64227273, 0.62651174, 0.62327791, 0.64227273,\n",
       "        0.62775801, 0.62342599, 0.64227273, 0.62775801, 0.62342599,\n",
       "        0.64227273, 0.62775801, 0.62342599, 0.64258123, 0.6265175 ,\n",
       "        0.62644902, 0.64258123, 0.6265175 , 0.62644902, 0.64258123,\n",
       "        0.6265175 , 0.62644902, 0.63382594, 0.61141629, 0.60256101,\n",
       "        0.63155431, 0.61204013, 0.59582727, 0.63170218, 0.61875297,\n",
       "        0.60376448, 0.63308341, 0.61210816, 0.60565081, 0.63370049,\n",
       "        0.61210816, 0.6062364 , 0.63308341, 0.61210816, 0.60391021,\n",
       "        0.63402062, 0.61589719, 0.61434436, 0.63402062, 0.61589719,\n",
       "        0.61434436, 0.63402062, 0.61589719, 0.61434436, 0.61359867,\n",
       "        0.58398438, 0.57439446, 0.6110586 , 0.57409683, 0.57591366,\n",
       "        0.61618552, 0.5884362 , 0.57114722, 0.62104523, 0.58268102,\n",
       "        0.57848411, 0.61396885, 0.58743633, 0.57745098, 0.61759849,\n",
       "        0.58562728, 0.58151508, 0.62371134, 0.59694989, 0.58404489,\n",
       "        0.6253508 , 0.60179568, 0.58523424, 0.62183693, 0.60135135,\n",
       "        0.58187135, 0.58129285, 0.5745938 , 0.56710494, 0.58031592,\n",
       "        0.56613103, 0.56840551, 0.58587833, 0.5712881 , 0.57247617,\n",
       "        0.58922965, 0.57093681, 0.56561197, 0.5967625 , 0.57380254,\n",
       "        0.56420329, 0.59976048, 0.57923228, 0.57282742, 0.60502994,\n",
       "        0.58329262, 0.57198921, 0.60807261, 0.57971721, 0.57114722,\n",
       "        0.6078853 , 0.58223524, 0.57446283, 0.64227273, 0.62392755,\n",
       "        0.62577271, 0.64227273, 0.62392755, 0.62577271, 0.64227273,\n",
       "        0.62651174, 0.62327791, 0.64227273, 0.62775801, 0.62342599,\n",
       "        0.64227273, 0.62775801, 0.62342599, 0.64227273, 0.62775801,\n",
       "        0.62342599, 0.64258123, 0.6265175 , 0.62644902, 0.64258123,\n",
       "        0.6265175 , 0.62644902, 0.64258123, 0.6265175 , 0.62644902,\n",
       "        0.63382594, 0.61534772, 0.60275296, 0.63155431, 0.61108457,\n",
       "        0.59439528, 0.63263873, 0.61369076, 0.60520555, 0.6325188 ,\n",
       "        0.62023217, 0.60565081, 0.63370049, 0.62023217, 0.60638298,\n",
       "        0.6325188 , 0.61210816, 0.60661676, 0.63402062, 0.61589719,\n",
       "        0.61434436, 0.63402062, 0.61589719, 0.61434436, 0.63402062,\n",
       "        0.61589719, 0.61434436, 0.61108479, 0.58040756, 0.5727003 ,\n",
       "        0.61057123, 0.58143522, 0.57360531, 0.61345927, 0.58766155,\n",
       "        0.5697417 , 0.61400189, 0.58618146, 0.57177974, 0.62000939,\n",
       "        0.59054545, 0.57836645, 0.61173118, 0.58786254, 0.57584683,\n",
       "        0.62529165, 0.60106126, 0.58427518, 0.62288931, 0.59649976,\n",
       "        0.58926829, 0.62619659, 0.59771789, 0.58008871, 0.58064516,\n",
       "        0.57170972, 0.56939327, 0.58028306, 0.57002698, 0.57522778,\n",
       "        0.58227848, 0.5621141 , 0.57065217, 0.59207347, 0.57756098,\n",
       "        0.57184967, 0.59670383, 0.57557853, 0.56622354, 0.59289683,\n",
       "        0.57583926, 0.57509248, 0.59923298, 0.57839551, 0.56909765,\n",
       "        0.60568426, 0.5834557 , 0.57432099, 0.61138909, 0.58752124,\n",
       "        0.5712881 ]),\n",
       " 'split2_test_f1': array([0.64757709, 0.64510166, 0.6430238 , 0.64757709, 0.64510166,\n",
       "        0.6430238 , 0.64757709, 0.64645997, 0.64419476, 0.64757709,\n",
       "        0.644429  , 0.64469378, 0.64757709, 0.644429  , 0.64469378,\n",
       "        0.64757709, 0.644429  , 0.64469378, 0.64786249, 0.64761466,\n",
       "        0.64470918, 0.64786249, 0.64761466, 0.64470918, 0.64786249,\n",
       "        0.64761466, 0.64470918, 0.65279704, 0.62910128, 0.6174206 ,\n",
       "        0.65662651, 0.63100333, 0.61583152, 0.65201296, 0.62997379,\n",
       "        0.62054002, 0.65276813, 0.63323033, 0.61345551, 0.65869915,\n",
       "        0.63495838, 0.61277832, 0.64950128, 0.63323033, 0.61575524,\n",
       "        0.6534104 , 0.63908702, 0.62295082, 0.6534104 , 0.63510942,\n",
       "        0.62130751, 0.6534104 , 0.63787375, 0.62295082, 0.62633452,\n",
       "        0.58829365, 0.58820627, 0.62815026, 0.59290291, 0.58678501,\n",
       "        0.63067367, 0.59965762, 0.58640297, 0.63867925, 0.60014638,\n",
       "        0.58579882, 0.63056275, 0.60214008, 0.59029318, 0.63100592,\n",
       "        0.60204082, 0.59430255, 0.63565891, 0.61296565, 0.59642245,\n",
       "        0.64289066, 0.6116104 , 0.58599357, 0.64059939, 0.61583012,\n",
       "        0.59663661, 0.60126275, 0.5873679 , 0.58458508, 0.59141882,\n",
       "        0.58206013, 0.57678087, 0.61020212, 0.58481262, 0.58598726,\n",
       "        0.6165234 , 0.58192506, 0.58029557, 0.60671985, 0.59116427,\n",
       "        0.58835047, 0.61020212, 0.58173785, 0.57690418, 0.61748503,\n",
       "        0.59502924, 0.57633775, 0.61989428, 0.59701493, 0.58310894,\n",
       "        0.62123386, 0.60058594, 0.58398438, 0.64757709, 0.64510166,\n",
       "        0.6430238 , 0.64757709, 0.64510166, 0.6430238 , 0.64757709,\n",
       "        0.64645997, 0.64419476, 0.64757709, 0.644429  , 0.64469378,\n",
       "        0.64757709, 0.644429  , 0.64469378, 0.64757709, 0.644429  ,\n",
       "        0.64469378, 0.64786249, 0.64761466, 0.64470918, 0.64786249,\n",
       "        0.64761466, 0.64470918, 0.64786249, 0.64761466, 0.64470918,\n",
       "        0.6552522 , 0.62754491, 0.60707364, 0.65228485, 0.63130352,\n",
       "        0.61004611, 0.65216385, 0.62925089, 0.61803199, 0.6537037 ,\n",
       "        0.63290537, 0.61590361, 0.65276813, 0.62846227, 0.61542169,\n",
       "        0.65339199, 0.63727359, 0.61929909, 0.6534104 , 0.63908702,\n",
       "        0.62130751, 0.6534104 , 0.63510942, 0.62130751, 0.6534104 ,\n",
       "        0.63510942, 0.62130751, 0.62730279, 0.598779  , 0.58498024,\n",
       "        0.63632075, 0.60322896, 0.58555885, 0.62996219, 0.60469667,\n",
       "        0.57824803, 0.6245283 , 0.5985864 , 0.58679707, 0.62963838,\n",
       "        0.59828641, 0.58557006, 0.63274441, 0.60254528, 0.58768702,\n",
       "        0.63676919, 0.6086324 , 0.60243902, 0.63924794, 0.61214614,\n",
       "        0.59105353, 0.64273985, 0.61549637, 0.5993117 , 0.59825328,\n",
       "        0.58218504, 0.58312898, 0.58817782, 0.57871287, 0.57950356,\n",
       "        0.61033317, 0.58504073, 0.57652303, 0.60667147, 0.58564077,\n",
       "        0.58109109, 0.60875808, 0.59308315, 0.58316929, 0.61051116,\n",
       "        0.59289883, 0.58667973, 0.62080537, 0.59936446, 0.57669617,\n",
       "        0.62133142, 0.60029283, 0.57670525, 0.6190362 , 0.59546452,\n",
       "        0.58290723]),\n",
       " 'split3_test_f1': array([0.64040943, 0.63343522, 0.62547348, 0.64040943, 0.63343522,\n",
       "        0.62547348, 0.64040943, 0.62897527, 0.62600473, 0.64040943,\n",
       "        0.63068584, 0.62289642, 0.64040943, 0.63068584, 0.62289642,\n",
       "        0.64040943, 0.63068584, 0.62289642, 0.64040943, 0.62892192,\n",
       "        0.625     , 0.64040943, 0.62892192, 0.625     , 0.64040943,\n",
       "        0.62892192, 0.625     , 0.64195804, 0.62075517, 0.61100478,\n",
       "        0.64252553, 0.62502946, 0.61509074, 0.64122848, 0.61745919,\n",
       "        0.61177597, 0.64153562, 0.62065706, 0.61333333, 0.64153562,\n",
       "        0.62080378, 0.61333333, 0.64109083, 0.62189643, 0.6130031 ,\n",
       "        0.64753529, 0.62987318, 0.62508893, 0.64753529, 0.62987318,\n",
       "        0.62508893, 0.64753529, 0.62987318, 0.62508893, 0.61379148,\n",
       "        0.59047619, 0.59019608, 0.61862424, 0.59839845, 0.58909802,\n",
       "        0.61961332, 0.60336538, 0.59333171, 0.62671952, 0.60159845,\n",
       "        0.58978744, 0.62816901, 0.61092477, 0.60082504, 0.62149533,\n",
       "        0.60502173, 0.59793814, 0.63420317, 0.61165747, 0.59878493,\n",
       "        0.62988076, 0.62116858, 0.60014602, 0.63231522, 0.60963336,\n",
       "        0.6062954 , 0.59980989, 0.59005146, 0.58743633, 0.60296226,\n",
       "        0.58599658, 0.58225373, 0.60372849, 0.59111866, 0.59717487,\n",
       "        0.6011976 , 0.5880049 , 0.58653611, 0.60229995, 0.58739887,\n",
       "        0.58682927, 0.5967858 , 0.58156028, 0.58812026, 0.61244019,\n",
       "        0.59864275, 0.58439024, 0.61758399, 0.59820345, 0.58642578,\n",
       "        0.61083274, 0.59530153, 0.58832117, 0.64040943, 0.63343522,\n",
       "        0.62547348, 0.64040943, 0.63343522, 0.62547348, 0.64040943,\n",
       "        0.62897527, 0.62600473, 0.64040943, 0.63068584, 0.62289642,\n",
       "        0.64040943, 0.63068584, 0.62289642, 0.64040943, 0.63068584,\n",
       "        0.62289642, 0.64040943, 0.62892192, 0.625     , 0.64040943,\n",
       "        0.62892192, 0.625     , 0.64040943, 0.62892192, 0.625     ,\n",
       "        0.63630026, 0.62387494, 0.60738255, 0.64270712, 0.61858595,\n",
       "        0.60804983, 0.64191228, 0.62576978, 0.61296473, 0.64153562,\n",
       "        0.62080378, 0.6126727 , 0.64109083, 0.62189643, 0.6130031 ,\n",
       "        0.64109083, 0.62065706, 0.6130031 , 0.64753529, 0.62987318,\n",
       "        0.62508893, 0.64753529, 0.62987318, 0.62508893, 0.64753529,\n",
       "        0.62987318, 0.62508893, 0.62126866, 0.60169287, 0.5998062 ,\n",
       "        0.61477511, 0.6022233 , 0.59431651, 0.6202058 , 0.60416667,\n",
       "        0.59381845, 0.62226406, 0.6042471 , 0.59643989, 0.6202205 ,\n",
       "        0.6002893 , 0.59414634, 0.62803738, 0.60846433, 0.59010774,\n",
       "        0.63224006, 0.61523672, 0.59951807, 0.63111318, 0.62014388,\n",
       "        0.59965762, 0.62978525, 0.61076406, 0.60276632, 0.59831933,\n",
       "        0.59429129, 0.57998037, 0.59827834, 0.59302326, 0.58408813,\n",
       "        0.60521906, 0.59325734, 0.58935547, 0.59423077, 0.59438339,\n",
       "        0.58826394, 0.59802267, 0.58881498, 0.58232833, 0.59749035,\n",
       "        0.5779636 , 0.58535391, 0.61457837, 0.60024242, 0.58937667,\n",
       "        0.61590038, 0.59805825, 0.58700921, 0.61575293, 0.59824903,\n",
       "        0.58497447]),\n",
       " 'split4_test_f1': array([0.66291376, 0.65281058, 0.64565063, 0.66291376, 0.65281058,\n",
       "        0.64565063, 0.66291376, 0.65281058, 0.6411597 , 0.66291376,\n",
       "        0.64658444, 0.64245014, 0.66291376, 0.64658444, 0.64245014,\n",
       "        0.66291376, 0.64658444, 0.64245014, 0.66291376, 0.65154737,\n",
       "        0.64389778, 0.66291376, 0.65154737, 0.64389778, 0.66291376,\n",
       "        0.65154737, 0.64389778, 0.64918033, 0.63192957, 0.61269995,\n",
       "        0.65224471, 0.63335713, 0.62175915, 0.64730679, 0.63965885,\n",
       "        0.62650024, 0.64918033, 0.6320038 , 0.61881668, 0.64918033,\n",
       "        0.63052305, 0.61560624, 0.64918033, 0.63232851, 0.61881668,\n",
       "        0.64925373, 0.63939106, 0.62986078, 0.64925373, 0.63939106,\n",
       "        0.62986078, 0.64925373, 0.63939106, 0.62986078, 0.62535885,\n",
       "        0.60325283, 0.6       , 0.62667304, 0.59921415, 0.59560819,\n",
       "        0.62215841, 0.60514076, 0.59916236, 0.62371257, 0.60782396,\n",
       "        0.59960938, 0.62329586, 0.60503791, 0.60103118, 0.6280517 ,\n",
       "        0.60648939, 0.60500491, 0.62523901, 0.61549672, 0.59965762,\n",
       "        0.62673031, 0.61433779, 0.6055855 , 0.62065683, 0.61538462,\n",
       "        0.61147741, 0.60214008, 0.59447568, 0.59246406, 0.60782884,\n",
       "        0.59527326, 0.58730159, 0.60797665, 0.59242871, 0.59181172,\n",
       "        0.60508309, 0.59770115, 0.58884247, 0.60749698, 0.59108717,\n",
       "        0.59114265, 0.5998544 , 0.59121041, 0.58936014, 0.60983289,\n",
       "        0.59533742, 0.58609678, 0.6089697 , 0.60303475, 0.59317456,\n",
       "        0.60930683, 0.60098039, 0.59322447, 0.66291376, 0.65281058,\n",
       "        0.64565063, 0.66291376, 0.65281058, 0.64565063, 0.66291376,\n",
       "        0.65281058, 0.6411597 , 0.66291376, 0.64658444, 0.64245014,\n",
       "        0.66291376, 0.64658444, 0.64245014, 0.66291376, 0.64658444,\n",
       "        0.64245014, 0.66291376, 0.65154737, 0.64389778, 0.66291376,\n",
       "        0.65154737, 0.64389778, 0.66291376, 0.65154737, 0.64389778,\n",
       "        0.64918033, 0.62637363, 0.61634917, 0.64902833, 0.6327065 ,\n",
       "        0.6167147 , 0.64730679, 0.63901398, 0.62205104, 0.64918033,\n",
       "        0.63052305, 0.61848169, 0.64918033, 0.63232851, 0.61560624,\n",
       "        0.64918033, 0.63232851, 0.61560624, 0.64925373, 0.63939106,\n",
       "        0.62986078, 0.64925373, 0.63939106, 0.62986078, 0.64925373,\n",
       "        0.63939106, 0.62986078, 0.6241033 , 0.59645669, 0.59705882,\n",
       "        0.62541806, 0.60210836, 0.59161914, 0.61862581, 0.60272639,\n",
       "        0.59567142, 0.62667304, 0.60635697, 0.59382656, 0.6290091 ,\n",
       "        0.60410557, 0.59578638, 0.62304547, 0.60327548, 0.60058451,\n",
       "        0.63090129, 0.60528229, 0.59887832, 0.62874822, 0.6089277 ,\n",
       "        0.60613437, 0.62600854, 0.6121756 , 0.60620875, 0.60692662,\n",
       "        0.59039686, 0.58665339, 0.60362757, 0.58646986, 0.58528095,\n",
       "        0.60797665, 0.59255608, 0.58893281, 0.60491126, 0.58829341,\n",
       "        0.58463796, 0.60812772, 0.59636185, 0.59488692, 0.60397479,\n",
       "        0.59517426, 0.59181172, 0.61374637, 0.59627634, 0.59528487,\n",
       "        0.61389961, 0.59094247, 0.59604589, 0.61174197, 0.59667156,\n",
       "        0.59466079]),\n",
       " 'mean_test_f1': array([0.64893631, 0.63931993, 0.63671976, 0.64893631, 0.63931993,\n",
       "        0.63671976, 0.64893631, 0.63921644, 0.63573622, 0.64893631,\n",
       "        0.63863564, 0.63541493, 0.64893631, 0.63863564, 0.63541493,\n",
       "        0.64893631, 0.63863564, 0.63541493, 0.64902661, 0.63904311,\n",
       "        0.63636243, 0.64902661, 0.63904311, 0.63636243, 0.64902661,\n",
       "        0.63904311, 0.63636243, 0.64630734, 0.62678843, 0.61270421,\n",
       "        0.64728874, 0.62717995, 0.61265136, 0.64505482, 0.62774155,\n",
       "        0.61764931, 0.64619754, 0.62774415, 0.61644519, 0.64738174,\n",
       "        0.6278497 , 0.61495824, 0.64545521, 0.62784486, 0.61649097,\n",
       "        0.6478296 , 0.63275174, 0.6239166 , 0.6478296 , 0.63361303,\n",
       "        0.62274198, 0.64809974, 0.63416589, 0.62386374, 0.62317054,\n",
       "        0.59265887, 0.58936829, 0.62409235, 0.59118505, 0.58820153,\n",
       "        0.62415106, 0.59940873, 0.58908829, 0.62992568, 0.60017188,\n",
       "        0.58970318, 0.62689088, 0.60273607, 0.59129843, 0.62829241,\n",
       "        0.60046607, 0.59482929, 0.63166892, 0.61143819, 0.59600056,\n",
       "        0.63357195, 0.61282936, 0.59397286, 0.63090899, 0.61169684,\n",
       "        0.59946239, 0.59678528, 0.58737125, 0.58486227, 0.59813071,\n",
       "        0.58376708, 0.58016918, 0.60314473, 0.58309928, 0.58738161,\n",
       "        0.60514278, 0.58613988, 0.58311493, 0.60372382, 0.58896684,\n",
       "        0.5856999 , 0.60413855, 0.58639191, 0.58377615, 0.6128837 ,\n",
       "        0.59354663, 0.58216755, 0.61452824, 0.5952063 , 0.58544825,\n",
       "        0.61340794, 0.59501154, 0.58660149, 0.64893631, 0.63931993,\n",
       "        0.63671976, 0.64893631, 0.63931993, 0.63671976, 0.64893631,\n",
       "        0.63921644, 0.63573622, 0.64893631, 0.63863564, 0.63541493,\n",
       "        0.64893631, 0.63863564, 0.63541493, 0.64893631, 0.63863564,\n",
       "        0.63541493, 0.64902661, 0.63904311, 0.63636243, 0.64902661,\n",
       "        0.63904311, 0.63636243, 0.64902661, 0.63904311, 0.63636243,\n",
       "        0.64511864, 0.62577993, 0.61047717, 0.64556968, 0.62542344,\n",
       "        0.60934215, 0.64540907, 0.62876192, 0.61578859, 0.64604513,\n",
       "        0.6290639 , 0.61673568, 0.64600539, 0.62872816, 0.61552544,\n",
       "        0.64595594, 0.62861774, 0.61709896, 0.64809974, 0.63275174,\n",
       "        0.62358794, 0.6478296 , 0.6332748 , 0.62274198, 0.6478296 ,\n",
       "        0.63195622, 0.62274198, 0.62518626, 0.59718502, 0.58972099,\n",
       "        0.62519873, 0.59910094, 0.58681259, 0.62318795, 0.60101778,\n",
       "        0.58490885, 0.62612202, 0.60054708, 0.58922342, 0.62826261,\n",
       "        0.60180557, 0.59096164, 0.62676926, 0.60303075, 0.58900213,\n",
       "        0.6330855 , 0.60955335, 0.59663627, 0.63221647, 0.6111905 ,\n",
       "        0.59647066, 0.63313679, 0.60982717, 0.59721307, 0.59776137,\n",
       "        0.58525307, 0.58153669, 0.59523878, 0.58378797, 0.58370706,\n",
       "        0.60220394, 0.58526626, 0.58263437, 0.60276545, 0.58847047,\n",
       "        0.58250584, 0.60602188, 0.5905389 , 0.58503541, 0.60267593,\n",
       "        0.58799951, 0.58528757, 0.61478655, 0.59350566, 0.58409949,\n",
       "        0.61518406, 0.59470718, 0.58561926, 0.61606258, 0.59621619,\n",
       "        0.58615588]),\n",
       " 'std_test_f1': array([0.00801179, 0.00990959, 0.00910206, 0.00801179, 0.00990959,\n",
       "        0.00910206, 0.00801179, 0.01007973, 0.00916397, 0.00801179,\n",
       "        0.00779909, 0.01003166, 0.00801179, 0.00779909, 0.01003166,\n",
       "        0.00801179, 0.00779909, 0.01003166, 0.0079433 , 0.0099159 ,\n",
       "        0.00875126, 0.0079433 , 0.0099159 , 0.00875126, 0.0079433 ,\n",
       "        0.0099159 , 0.00875126, 0.00749457, 0.00999126, 0.00598099,\n",
       "        0.00917065, 0.00824324, 0.00879161, 0.00787304, 0.00848239,\n",
       "        0.00869764, 0.00791702, 0.01011299, 0.00838717, 0.00887443,\n",
       "        0.01023974, 0.00670799, 0.00751968, 0.00971341, 0.0087866 ,\n",
       "        0.00740723, 0.00918973, 0.0053099 , 0.00740723, 0.0106261 ,\n",
       "        0.00507735, 0.00768075, 0.01076064, 0.00527678, 0.00870988,\n",
       "        0.00682232, 0.00849886, 0.00852809, 0.00907165, 0.00689687,\n",
       "        0.00623104, 0.00583165, 0.0098832 , 0.00768763, 0.00935645,\n",
       "        0.00728833, 0.00810945, 0.00819764, 0.00891812, 0.00887161,\n",
       "        0.00757514, 0.00762973, 0.00614557, 0.00779947, 0.00616725,\n",
       "        0.00779594, 0.00633767, 0.00792634, 0.00837835, 0.00570998,\n",
       "        0.01010883, 0.00780809, 0.00678081, 0.00939757, 0.01076805,\n",
       "        0.00982597, 0.00693262, 0.00888369, 0.00832304, 0.00829412,\n",
       "        0.00970774, 0.00918628, 0.00983525, 0.0039067 , 0.00889785,\n",
       "        0.01140769, 0.00674361, 0.00720217, 0.00747588, 0.00525121,\n",
       "        0.00529285, 0.00714296, 0.00497212, 0.00801998, 0.00816861,\n",
       "        0.00518302, 0.00679571, 0.0069591 , 0.00801179, 0.00990959,\n",
       "        0.00910206, 0.00801179, 0.00990959, 0.00910206, 0.00801179,\n",
       "        0.01007973, 0.00916397, 0.00801179, 0.00779909, 0.01003166,\n",
       "        0.00801179, 0.00779909, 0.01003166, 0.00801179, 0.00779909,\n",
       "        0.01003166, 0.0079433 , 0.0099159 , 0.00875126, 0.0079433 ,\n",
       "        0.0099159 , 0.00875126, 0.0079433 , 0.0099159 , 0.00875126,\n",
       "        0.00847906, 0.00656503, 0.00608331, 0.00783104, 0.00899094,\n",
       "        0.00832536, 0.00751691, 0.00888878, 0.0061359 , 0.00805268,\n",
       "        0.00777364, 0.00831538, 0.00754192, 0.00742597, 0.00673153,\n",
       "        0.00810328, 0.01068767, 0.00807609, 0.00768075, 0.00918973,\n",
       "        0.00540943, 0.00740723, 0.01018718, 0.00507735, 0.00740723,\n",
       "        0.00876943, 0.00507735, 0.01008325, 0.00932657, 0.00986464,\n",
       "        0.0112634 , 0.0089754 , 0.00721167, 0.00748956, 0.00675261,\n",
       "        0.00973931, 0.00953238, 0.00779902, 0.00946831, 0.00819899,\n",
       "        0.00827816, 0.00800844, 0.00905538, 0.00847823, 0.00791634,\n",
       "        0.00511422, 0.00612402, 0.00635386, 0.00627443, 0.00838617,\n",
       "        0.00607975, 0.00725995, 0.00624692, 0.00905136, 0.00922111,\n",
       "        0.00783435, 0.00674494, 0.00964628, 0.00843179, 0.00643857,\n",
       "        0.01014469, 0.01198858, 0.00763558, 0.00872464, 0.00672416,\n",
       "        0.00584355, 0.00797955, 0.00820169, 0.01135699, 0.00662714,\n",
       "        0.00923611, 0.0055379 , 0.00889428, 0.00794693, 0.00967616,\n",
       "        0.00539574, 0.00663562, 0.00881187, 0.00423127, 0.00507792,\n",
       "        0.009185  ]),\n",
       " 'rank_test_f1': array([  7,  37,  55,   7,  37,  55,   7,  41,  65,   7,  49,  67,   7,\n",
       "         49,  67,   7,  49,  67,   1,  43,  59,   1,  43,  59,   1,  43,\n",
       "         59,  27,  98, 130,  26,  96, 131,  36,  95, 115,  28,  94, 119,\n",
       "         25,  92, 124,  33,  93, 118,  21,  79, 107,  21,  74, 112,  19,\n",
       "         73, 108, 111, 174, 181, 106, 176, 187, 105, 155, 183,  85, 153,\n",
       "        180,  97, 146, 175,  90, 152, 169,  83, 133, 165,  75, 129, 171,\n",
       "         84, 132, 154, 161, 190, 204, 157, 208, 216, 143, 211, 189, 140,\n",
       "        195, 210, 142, 185, 196, 141, 193, 207, 128, 172, 214, 126, 167,\n",
       "        198, 127, 168, 192,   7,  37,  55,   7,  37,  55,   7,  41,  65,\n",
       "          7,  49,  67,   7,  49,  67,   7,  49,  67,   1,  43,  59,   1,\n",
       "         43,  59,   1,  43,  59,  35, 101, 135,  32, 102, 138,  34,  87,\n",
       "        121,  29,  86, 117,  30,  88, 122,  31,  89, 116,  19,  79, 109,\n",
       "         21,  76, 112,  21,  82, 112, 104, 160, 179, 103, 156, 191, 110,\n",
       "        150, 203, 100, 151, 182,  91, 149, 177,  99, 144, 184,  78, 137,\n",
       "        162,  81, 134, 163,  77, 136, 159, 158, 201, 215, 166, 206, 209,\n",
       "        148, 200, 212, 145, 186, 213, 139, 178, 202, 147, 188, 199, 125,\n",
       "        173, 205, 123, 170, 197, 120, 164, 194]),\n",
       " 'split0_test_precision': array([0.58939873, 0.6132917 , 0.61885431, 0.58939873, 0.6132917 ,\n",
       "        0.61885431, 0.58939873, 0.6132917 , 0.61787158, 0.58939873,\n",
       "        0.61401952, 0.6166592 , 0.58939873, 0.61401952, 0.6166592 ,\n",
       "        0.58939873, 0.61401952, 0.6166592 , 0.58916568, 0.61118509,\n",
       "        0.61449016, 0.58916568, 0.61118509, 0.61449016, 0.58916568,\n",
       "        0.61118509, 0.61449016, 0.61792863, 0.62229387, 0.61653772,\n",
       "        0.61665221, 0.61524334, 0.61221522, 0.61658706, 0.61967213,\n",
       "        0.61996161, 0.61715028, 0.62269373, 0.62285714, 0.6171875 ,\n",
       "        0.62338262, 0.61805226, 0.61715028, 0.61727273, 0.62285714,\n",
       "        0.61538462, 0.61699228, 0.61581921, 0.61538462, 0.62608299,\n",
       "        0.61265942, 0.61777394, 0.62608299, 0.61713204, 0.61274288,\n",
       "        0.60278746, 0.60332661, 0.61545496, 0.59720837, 0.6024157 ,\n",
       "        0.61      , 0.60566882, 0.60300752, 0.61776765, 0.61623246,\n",
       "        0.60443996, 0.61503623, 0.61023622, 0.59636731, 0.61984594,\n",
       "        0.60763889, 0.60453401, 0.6132795 , 0.61519962, 0.61111111,\n",
       "        0.61555655, 0.61463415, 0.60201511, 0.61462094, 0.61478599,\n",
       "        0.60384805, 0.59199237, 0.59989909, 0.60060211, 0.60201149,\n",
       "        0.59889001, 0.5952621 , 0.6021093 , 0.58817533, 0.59699248,\n",
       "        0.60493827, 0.6035533 , 0.59871032, 0.60125362, 0.60707171,\n",
       "        0.60469765, 0.604354  , 0.60571142, 0.60417728, 0.60867515,\n",
       "        0.59851852, 0.6002009 , 0.60803783, 0.60849772, 0.60405063,\n",
       "        0.60601787, 0.60159363, 0.60120542, 0.58939873, 0.6132917 ,\n",
       "        0.61885431, 0.58939873, 0.6132917 , 0.61885431, 0.58939873,\n",
       "        0.6132917 , 0.61787158, 0.58939873, 0.61401952, 0.6166592 ,\n",
       "        0.58939873, 0.61401952, 0.6166592 , 0.58939873, 0.61401952,\n",
       "        0.6166592 , 0.58916568, 0.61118509, 0.61449016, 0.58916568,\n",
       "        0.61118509, 0.61449016, 0.58916568, 0.61118509, 0.61449016,\n",
       "        0.61458333, 0.61898148, 0.61598063, 0.6152513 , 0.61853749,\n",
       "        0.61100478, 0.61658706, 0.6161246 , 0.61679537, 0.61861075,\n",
       "        0.62338262, 0.62285714, 0.61861075, 0.62269373, 0.6225325 ,\n",
       "        0.61877729, 0.62269373, 0.62285714, 0.61777394, 0.61699228,\n",
       "        0.61581921, 0.61538462, 0.62335302, 0.61265942, 0.61538462,\n",
       "        0.61699228, 0.61265942, 0.61607544, 0.61113849, 0.60180542,\n",
       "        0.61587302, 0.6119403 , 0.59649123, 0.61164166, 0.60807484,\n",
       "        0.59777102, 0.61995465, 0.6141929 , 0.60583208, 0.62117754,\n",
       "        0.62022806, 0.60769615, 0.61514053, 0.61557417, 0.60233621,\n",
       "        0.61580135, 0.61441703, 0.60540811, 0.6124552 , 0.61673152,\n",
       "        0.60370741, 0.61424731, 0.61208577, 0.60108749, 0.60086873,\n",
       "        0.59489234, 0.59818274, 0.59705743, 0.5975    , 0.59900744,\n",
       "        0.59771211, 0.60140562, 0.59858084, 0.60702421, 0.60625946,\n",
       "        0.59646465, 0.60968661, 0.60962025, 0.60438465, 0.60181644,\n",
       "        0.605     , 0.6013306 , 0.61422515, 0.59811227, 0.59819186,\n",
       "        0.60675739, 0.60435213, 0.60641548, 0.61082353, 0.60273304,\n",
       "        0.60109019]),\n",
       " 'split1_test_precision': array([0.6       , 0.60855416, 0.60897733, 0.6       , 0.60855416,\n",
       "        0.60897733, 0.6       , 0.60819521, 0.60600462, 0.6       ,\n",
       "        0.60967742, 0.60628466, 0.6       , 0.60967742, 0.60628466,\n",
       "        0.6       , 0.60967742, 0.60628466, 0.60016978, 0.61038961,\n",
       "        0.60678277, 0.60016978, 0.61038961, 0.60678277, 0.60016978,\n",
       "        0.61038961, 0.60678277, 0.6091073 , 0.59757236, 0.59551098,\n",
       "        0.60574764, 0.59831854, 0.59123736, 0.60601977, 0.60268892,\n",
       "        0.59599809, 0.60773729, 0.59934396, 0.59828244, 0.60846085,\n",
       "        0.59934396, 0.59942639, 0.60773729, 0.59934396, 0.59628217,\n",
       "        0.60863698, 0.59990728, 0.60687023, 0.60863698, 0.59990728,\n",
       "        0.60687023, 0.60863698, 0.59990728, 0.60687023, 0.59512868,\n",
       "        0.58313018, 0.58070965, 0.59122085, 0.5770751 , 0.57775591,\n",
       "        0.59697387, 0.58714703, 0.57511155, 0.59630963, 0.58296623,\n",
       "        0.57848411, 0.59325125, 0.5827719 , 0.57886978, 0.59662716,\n",
       "        0.58349515, 0.58308751, 0.59874044, 0.59108341, 0.58276534,\n",
       "        0.59928283, 0.5973025 , 0.5871063 , 0.59694107, 0.59361601,\n",
       "        0.57989315, 0.58214811, 0.57858205, 0.5755287 , 0.57681159,\n",
       "        0.5725    , 0.57206538, 0.58544922, 0.57439446, 0.57233627,\n",
       "        0.58206107, 0.57418398, 0.56742126, 0.58978032, 0.57352223,\n",
       "        0.56656805, 0.58779343, 0.58296186, 0.57352941, 0.59295775,\n",
       "        0.58272328, 0.5738189 , 0.59430439, 0.57802625, 0.57511155,\n",
       "        0.59439252, 0.58110083, 0.58033932, 0.6       , 0.60855416,\n",
       "        0.60897733, 0.6       , 0.60855416, 0.60897733, 0.6       ,\n",
       "        0.60819521, 0.60600462, 0.6       , 0.60967742, 0.60628466,\n",
       "        0.6       , 0.60967742, 0.60628466, 0.6       , 0.60967742,\n",
       "        0.60628466, 0.60016978, 0.61038961, 0.60678277, 0.60016978,\n",
       "        0.61038961, 0.60678277, 0.60016978, 0.61038961, 0.60678277,\n",
       "        0.6091073 , 0.60376471, 0.59541985, 0.60574764, 0.5973844 ,\n",
       "        0.59762729, 0.60691824, 0.60103141, 0.60212972, 0.60877431,\n",
       "        0.6015625 , 0.59828244, 0.60846085, 0.6015625 , 0.59971306,\n",
       "        0.60877431, 0.59934396, 0.59923664, 0.60863698, 0.59990728,\n",
       "        0.60687023, 0.60863698, 0.59990728, 0.60687023, 0.60863698,\n",
       "        0.59990728, 0.60687023, 0.59255857, 0.58284024, 0.57928964,\n",
       "        0.5924563 , 0.58243376, 0.57658103, 0.59315068, 0.58608949,\n",
       "        0.57326733, 0.59459459, 0.58951533, 0.57488878, 0.59647537,\n",
       "        0.58557692, 0.58021654, 0.59464451, 0.58600583, 0.5781173 ,\n",
       "        0.59794734, 0.59305093, 0.58716049, 0.59846778, 0.59304012,\n",
       "        0.58783455, 0.59919571, 0.59353905, 0.58469945, 0.5803615 ,\n",
       "        0.57524752, 0.57206318, 0.57915246, 0.57185039, 0.57936508,\n",
       "        0.57973825, 0.56786427, 0.57663505, 0.58528428, 0.57615572,\n",
       "        0.5745311 , 0.59154253, 0.57957362, 0.57015369, 0.58595989,\n",
       "        0.57711198, 0.5800995 , 0.58768218, 0.57684825, 0.5755    ,\n",
       "        0.59197012, 0.58402744, 0.58004988, 0.59618959, 0.58341369,\n",
       "        0.57439446]),\n",
       " 'split2_test_precision': array([0.58917836, 0.61147613, 0.61490406, 0.58917836, 0.61147613,\n",
       "        0.61490406, 0.58917836, 0.61352657, 0.61787158, 0.58917836,\n",
       "        0.61223592, 0.61755486, 0.58917836, 0.61223592, 0.61755486,\n",
       "        0.58917836, 0.61223592, 0.61755486, 0.58965102, 0.61246731,\n",
       "        0.61717352, 0.58965102, 0.61246731, 0.61717352, 0.58965102,\n",
       "        0.61246731, 0.61717352, 0.61902674, 0.61221657, 0.60776883,\n",
       "        0.62395421, 0.61406756, 0.60977948, 0.61879666, 0.61431227,\n",
       "        0.61198288, 0.62015845, 0.61609621, 0.60513796, 0.62142238,\n",
       "        0.61805556, 0.60661236, 0.61782877, 0.61609621, 0.60683761,\n",
       "        0.61973684, 0.62193429, 0.61436044, 0.61973684, 0.61834182,\n",
       "        0.61534772, 0.61973684, 0.61964039, 0.61436044, 0.60829493,\n",
       "        0.59687972, 0.5936255 , 0.61129107, 0.5976155 , 0.5917454 ,\n",
       "        0.61653433, 0.59980431, 0.593     , 0.61685649, 0.59883155,\n",
       "        0.59075087, 0.60808356, 0.59893566, 0.59483615, 0.61146789,\n",
       "        0.59826171, 0.59694129, 0.61166365, 0.60651029, 0.59774067,\n",
       "        0.61795219, 0.60762548, 0.59318637, 0.61455526, 0.60790853,\n",
       "        0.59475219, 0.59720212, 0.59041502, 0.58878968, 0.58969373,\n",
       "        0.58668654, 0.58151093, 0.60066319, 0.58975634, 0.58713795,\n",
       "        0.6024265 , 0.58292444, 0.58461538, 0.5999044 , 0.59015595,\n",
       "        0.588927  , 0.60066319, 0.58403154, 0.57975309, 0.60516432,\n",
       "        0.59300631, 0.57861015, 0.60935286, 0.59745348, 0.58382353,\n",
       "        0.60786149, 0.59970746, 0.58313018, 0.58917836, 0.61147613,\n",
       "        0.61490406, 0.58917836, 0.61147613, 0.61490406, 0.58917836,\n",
       "        0.61352657, 0.61787158, 0.58917836, 0.61223592, 0.61755486,\n",
       "        0.58917836, 0.61223592, 0.61755486, 0.58917836, 0.61223592,\n",
       "        0.61755486, 0.58965102, 0.61246731, 0.61717352, 0.58965102,\n",
       "        0.61246731, 0.61717352, 0.58965102, 0.61246731, 0.61717352,\n",
       "        0.62187088, 0.61502347, 0.60153625, 0.62047661, 0.61463641,\n",
       "        0.60549133, 0.61906854, 0.6125    , 0.61268621, 0.62065934,\n",
       "        0.61591856, 0.60712589, 0.62015845, 0.61409239, 0.60665083,\n",
       "        0.62049252, 0.62157136, 0.60820368, 0.61973684, 0.62193429,\n",
       "        0.61534772, 0.61973684, 0.61834182, 0.61534772, 0.61973684,\n",
       "        0.61834182, 0.61534772, 0.60666971, 0.59804878, 0.59111333,\n",
       "        0.61457859, 0.60352423, 0.59229615, 0.60951075, 0.60499266,\n",
       "        0.58197127, 0.60318907, 0.59669582, 0.58679707, 0.60933211,\n",
       "        0.59901961, 0.58978175, 0.61045455, 0.60313572, 0.58956693,\n",
       "        0.61246612, 0.6036556 , 0.60097324, 0.61538462, 0.60584291,\n",
       "        0.59090909, 0.61767358, 0.60959233, 0.60257044, 0.59364468,\n",
       "        0.58593363, 0.58484998, 0.58760371, 0.58596491, 0.58250988,\n",
       "        0.60276586, 0.59072782, 0.58404415, 0.59566447, 0.58693517,\n",
       "        0.58673978, 0.59606373, 0.59498031, 0.58692422, 0.5994345 ,\n",
       "        0.58974359, 0.58754291, 0.60883874, 0.59921799, 0.57983193,\n",
       "        0.60671016, 0.59912323, 0.58085317, 0.60724365, 0.5938716 ,\n",
       "        0.58050436]),\n",
       " 'split3_test_precision': array([0.5878268 , 0.61033077, 0.60651974, 0.5878268 , 0.61033077,\n",
       "        0.60651974, 0.5878268 , 0.60709413, 0.60622711, 0.5878268 ,\n",
       "        0.60901229, 0.60469397, 0.5878268 , 0.60901229, 0.60469397,\n",
       "        0.5878268 , 0.60901229, 0.60469397, 0.5878268 , 0.60784314,\n",
       "        0.60606061, 0.5878268 , 0.60784314, 0.60606061, 0.5878268 ,\n",
       "        0.60784314, 0.60606061, 0.61363636, 0.60369515, 0.59840675,\n",
       "        0.61184792, 0.6035503 , 0.60130719, 0.61190053, 0.59834938,\n",
       "        0.59943715, 0.60886743, 0.60091533, 0.59795729, 0.60886743,\n",
       "        0.60119048, 0.59795729, 0.60806664, 0.60238204, 0.59777055,\n",
       "        0.61494505, 0.6062387 , 0.60709351, 0.61494505, 0.6062387 ,\n",
       "        0.60709351, 0.61494505, 0.6062387 , 0.60709351, 0.59192011,\n",
       "        0.59004392, 0.59193707, 0.59335727, 0.59421687, 0.58924205,\n",
       "        0.59190031, 0.59366131, 0.59088706, 0.5991975 , 0.5962554 ,\n",
       "        0.58964338, 0.60433604, 0.59915414, 0.59662651, 0.59534467,\n",
       "        0.59780534, 0.60059172, 0.60596616, 0.60056524, 0.59545674,\n",
       "        0.60376513, 0.60892019, 0.59767329, 0.60454748, 0.59802539,\n",
       "        0.60076775, 0.58371878, 0.59164619, 0.58305248, 0.58971963,\n",
       "        0.58499756, 0.58239609, 0.59073901, 0.58698795, 0.59514563,\n",
       "        0.58947863, 0.58901422, 0.58754291, 0.59069549, 0.58927693,\n",
       "        0.58568647, 0.58596326, 0.58198727, 0.58826406, 0.59981256,\n",
       "        0.59375   , 0.58325219, 0.60251046, 0.59430777, 0.58585366,\n",
       "        0.5967366 , 0.5900144 , 0.58575581, 0.5878268 , 0.61033077,\n",
       "        0.60651974, 0.5878268 , 0.61033077, 0.60651974, 0.5878268 ,\n",
       "        0.60709413, 0.60622711, 0.5878268 , 0.60901229, 0.60469397,\n",
       "        0.5878268 , 0.60901229, 0.60469397, 0.5878268 , 0.60901229,\n",
       "        0.60469397, 0.5878268 , 0.60784314, 0.60606061, 0.5878268 ,\n",
       "        0.60784314, 0.60606061, 0.5878268 , 0.60784314, 0.60606061,\n",
       "        0.60655738, 0.60523897, 0.59595484, 0.6150067 , 0.59917545,\n",
       "        0.59633459, 0.61113566, 0.60707721, 0.59813953, 0.60886743,\n",
       "        0.60119048, 0.59758364, 0.60806664, 0.60238204, 0.59777055,\n",
       "        0.60806664, 0.60091533, 0.59777055, 0.61494505, 0.6062387 ,\n",
       "        0.60709351, 0.61494505, 0.6062387 , 0.60709351, 0.61494505,\n",
       "        0.6062387 , 0.60709351, 0.5941124 , 0.59550024, 0.59462056,\n",
       "        0.58752784, 0.59560229, 0.59577603, 0.59461883, 0.59894332,\n",
       "        0.59137179, 0.60009079, 0.59675882, 0.59513382, 0.59630131,\n",
       "        0.59229305, 0.59298929, 0.60161146, 0.60220201, 0.59126595,\n",
       "        0.60319574, 0.60520095, 0.59125475, 0.60275801, 0.60875706,\n",
       "        0.6000979 , 0.60277033, 0.60066163, 0.59855422, 0.58801321,\n",
       "        0.59327813, 0.58226601, 0.58567416, 0.58789625, 0.58509073,\n",
       "        0.59314876, 0.58883004, 0.58878049, 0.5846736 , 0.59394827,\n",
       "        0.58612324, 0.59019515, 0.59364133, 0.58651463, 0.5900858 ,\n",
       "        0.58168317, 0.58664703, 0.59944238, 0.5954786 , 0.58497833,\n",
       "        0.60375587, 0.59402122, 0.58221154, 0.60347255, 0.59535334,\n",
       "        0.5820029 ]),\n",
       " 'split4_test_precision': array([0.61461378, 0.63162706, 0.62678325, 0.61461378, 0.63162706,\n",
       "        0.62678325, 0.61461378, 0.63162706, 0.6239593 , 0.61461378,\n",
       "        0.6281106 , 0.62465374, 0.61461378, 0.6281106 , 0.62465374,\n",
       "        0.61461378, 0.6281106 , 0.62465374, 0.61461378, 0.63054412,\n",
       "        0.62961233, 0.61461378, 0.63054412, 0.62961233, 0.61461378,\n",
       "        0.63054412, 0.62961233, 0.62320144, 0.61566991, 0.60769231,\n",
       "        0.6222814 , 0.61706073, 0.61653051, 0.62140288, 0.62068966,\n",
       "        0.61556604, 0.62320144, 0.61449677, 0.61405197, 0.62320144,\n",
       "        0.61653433, 0.60500236, 0.62320144, 0.61467467, 0.61405197,\n",
       "        0.62087422, 0.62279889, 0.61886792, 0.62087422, 0.62279889,\n",
       "        0.61886792, 0.62087422, 0.62279889, 0.61886792, 0.61246485,\n",
       "        0.6083499 , 0.60782347, 0.6131899 , 0.60217177, 0.60139512,\n",
       "        0.60947023, 0.6061795 , 0.60407352, 0.61155472, 0.60812133,\n",
       "        0.59902439, 0.61030445, 0.60548213, 0.60384805, 0.61538462,\n",
       "        0.60545543, 0.60738916, 0.61178672, 0.61178175, 0.6000979 ,\n",
       "        0.61240672, 0.61092315, 0.60707269, 0.60482375, 0.61108434,\n",
       "        0.61102977, 0.59922556, 0.59462103, 0.60110664, 0.60474117,\n",
       "        0.59970238, 0.59617321, 0.60503388, 0.59594461, 0.59370389,\n",
       "        0.60508309, 0.59813999, 0.59218982, 0.60124461, 0.5922473 ,\n",
       "        0.59186673, 0.59566265, 0.59398125, 0.59124447, 0.60441671,\n",
       "        0.59783144, 0.5891358 , 0.6041366 , 0.60392157, 0.59595461,\n",
       "        0.60432692, 0.6027532 , 0.59163831, 0.61461378, 0.63162706,\n",
       "        0.62678325, 0.61461378, 0.63162706, 0.62678325, 0.61461378,\n",
       "        0.63162706, 0.6239593 , 0.61461378, 0.6281106 , 0.62465374,\n",
       "        0.61461378, 0.6281106 , 0.62465374, 0.61461378, 0.6281106 ,\n",
       "        0.62465374, 0.61461378, 0.63054412, 0.62961233, 0.61461378,\n",
       "        0.63054412, 0.62961233, 0.61461378, 0.63054412, 0.62961233,\n",
       "        0.62320144, 0.61261682, 0.60828177, 0.62292135, 0.61670534,\n",
       "        0.60623229, 0.62140288, 0.62034054, 0.61290323, 0.62320144,\n",
       "        0.61653433, 0.61386615, 0.62320144, 0.61467467, 0.60500236,\n",
       "        0.62320144, 0.61467467, 0.60500236, 0.62087422, 0.62279889,\n",
       "        0.61886792, 0.62087422, 0.62279889, 0.61886792, 0.62087422,\n",
       "        0.62279889, 0.61886792, 0.61095506, 0.60059465, 0.59882006,\n",
       "        0.61168224, 0.60403345, 0.60040262, 0.60628813, 0.60038797,\n",
       "        0.59950495, 0.6131899 , 0.60665362, 0.59528487, 0.6163227 ,\n",
       "        0.60410557, 0.59724951, 0.61345334, 0.60342298, 0.59854369,\n",
       "        0.61592179, 0.60019222, 0.59756691, 0.61270872, 0.60452794,\n",
       "        0.60378274, 0.60839483, 0.60760713, 0.60635697, 0.60153625,\n",
       "        0.59184676, 0.59796954, 0.59741503, 0.59039128, 0.59564777,\n",
       "        0.60503388, 0.59771258, 0.5954046 , 0.60183841, 0.59460809,\n",
       "        0.58521058, 0.60201149, 0.59990109, 0.59841741, 0.59903846,\n",
       "        0.59358289, 0.59370389, 0.60786194, 0.59774067, 0.5982231 ,\n",
       "        0.60629171, 0.59195684, 0.59531936, 0.60487339, 0.59754902,\n",
       "        0.59597447]),\n",
       " 'mean_test_precision': array([0.59620353, 0.61505596, 0.61520774, 0.59620353, 0.61505596,\n",
       "        0.61520774, 0.59620353, 0.61474694, 0.61438683, 0.59620353,\n",
       "        0.61461115, 0.61396929, 0.59620353, 0.61461115, 0.61396929,\n",
       "        0.59620353, 0.61461115, 0.61396929, 0.59628541, 0.61448585,\n",
       "        0.61482388, 0.59628541, 0.61448585, 0.61482388, 0.59628541,\n",
       "        0.61448585, 0.61482388, 0.6165801 , 0.61028957, 0.60518332,\n",
       "        0.61609668, 0.60964809, 0.60621395, 0.61494138, 0.61114247,\n",
       "        0.60858915, 0.61542298, 0.6107092 , 0.60765736, 0.61582792,\n",
       "        0.61170139, 0.60541013, 0.61479688, 0.60995392, 0.60755989,\n",
       "        0.61591554, 0.61357429, 0.61260226, 0.61591554, 0.61467394,\n",
       "        0.61216776, 0.61639341, 0.61493365, 0.61286483, 0.60411029,\n",
       "        0.59623824, 0.59548446, 0.60490281, 0.59365752, 0.59251084,\n",
       "        0.60497575, 0.59849219, 0.59321593, 0.6083372 , 0.60048139,\n",
       "        0.59246854, 0.60620231, 0.59931601, 0.59410956, 0.60773406,\n",
       "        0.5985313 , 0.59850874, 0.60828729, 0.60502806, 0.59743435,\n",
       "        0.60979268, 0.60788109, 0.59741075, 0.6070977 , 0.60508405,\n",
       "        0.59805818, 0.59085739, 0.59103268, 0.58981592, 0.59259552,\n",
       "        0.5885553 , 0.58548154, 0.59679892, 0.58705174, 0.58906324,\n",
       "        0.59679751, 0.58956318, 0.58609594, 0.59657569, 0.59045482,\n",
       "        0.58754918, 0.59488731, 0.58973467, 0.58739366, 0.6022053 ,\n",
       "        0.59316591, 0.58500359, 0.60366843, 0.59644136, 0.5889588 ,\n",
       "        0.60186708, 0.5950339 , 0.58841381, 0.59620353, 0.61505596,\n",
       "        0.61520774, 0.59620353, 0.61505596, 0.61520774, 0.59620353,\n",
       "        0.61474694, 0.61438683, 0.59620353, 0.61461115, 0.61396929,\n",
       "        0.59620353, 0.61461115, 0.61396929, 0.59620353, 0.61461115,\n",
       "        0.61396929, 0.59628541, 0.61448585, 0.61482388, 0.59628541,\n",
       "        0.61448585, 0.61482388, 0.59628541, 0.61448585, 0.61482388,\n",
       "        0.61506407, 0.61112509, 0.60343467, 0.61588072, 0.60928782,\n",
       "        0.60333806, 0.61502248, 0.61141475, 0.60853081, 0.61602265,\n",
       "        0.6117177 , 0.60794305, 0.61569962, 0.61108107, 0.60633386,\n",
       "        0.61586244, 0.61183981, 0.60661407, 0.61639341, 0.61357429,\n",
       "        0.61279972, 0.61591554, 0.61412794, 0.61216776, 0.61591554,\n",
       "        0.61285579, 0.61216776, 0.60407423, 0.59762448, 0.5931298 ,\n",
       "        0.6044236 , 0.59950681, 0.59230941, 0.60304201, 0.59969766,\n",
       "        0.58877727, 0.6062038 , 0.6007633 , 0.59158732, 0.60792181,\n",
       "        0.60024464, 0.59358665, 0.60706088, 0.60206814, 0.59196602,\n",
       "        0.60906647, 0.60330334, 0.5964727 , 0.60835486, 0.60577991,\n",
       "        0.59726634, 0.60845635, 0.60469718, 0.59865371, 0.59288487,\n",
       "        0.58823968, 0.58706629, 0.58938056, 0.58672057, 0.58832418,\n",
       "        0.59567977, 0.58930807, 0.58868903, 0.59489699, 0.59158134,\n",
       "        0.58581387, 0.5978999 , 0.59554332, 0.58927892, 0.59526702,\n",
       "        0.58942433, 0.58986479, 0.60361008, 0.59347955, 0.58734505,\n",
       "        0.60309705, 0.59469617, 0.58896988, 0.60452054, 0.59458414,\n",
       "        0.58679328]),\n",
       " 'std_test_precision': array([0.01018998, 0.00842769, 0.00723438, 0.01018998, 0.00842769,\n",
       "        0.00723438, 0.01018998, 0.00883217, 0.00711002, 0.01018998,\n",
       "        0.00698449, 0.00747442, 0.01018998, 0.00698449, 0.00747442,\n",
       "        0.01018998, 0.00698449, 0.00747442, 0.01017125, 0.00816998,\n",
       "        0.00855319, 0.01017125, 0.00816998, 0.00855319, 0.01017125,\n",
       "        0.00816998, 0.00855319, 0.00481985, 0.00874046, 0.00750171,\n",
       "        0.00671498, 0.00736651, 0.0089837 , 0.00544361, 0.00904519,\n",
       "        0.00929324, 0.00613119, 0.00907836, 0.00959429, 0.00616826,\n",
       "        0.00962673, 0.00711035, 0.00600835, 0.00752971, 0.00999693,\n",
       "        0.00432185, 0.00902512, 0.00481458, 0.00432185, 0.00998842,\n",
       "        0.00467029, 0.00436857, 0.0100967 , 0.00501451, 0.00884422,\n",
       "        0.00894636, 0.00946663, 0.01040509, 0.00867244, 0.00901128,\n",
       "        0.00909991, 0.00727146, 0.01045946, 0.00894495, 0.01125901,\n",
       "        0.0088633 , 0.00734326, 0.00928602, 0.00823468, 0.00996022,\n",
       "        0.00845668, 0.00848264, 0.00538698, 0.00855149, 0.00909212,\n",
       "        0.00711929, 0.00579499, 0.00690868, 0.00673863, 0.00799312,\n",
       "        0.01048832, 0.0069048 , 0.00703229, 0.0099473 , 0.01001999,\n",
       "        0.01004974, 0.00911318, 0.0074362 , 0.0070409 , 0.00899891,\n",
       "        0.0093524 , 0.0104898 , 0.01048129, 0.00520607, 0.01065386,\n",
       "        0.01231493, 0.00712098, 0.00907424, 0.01046778, 0.00541752,\n",
       "        0.0056539 , 0.00913317, 0.00530377, 0.0104499 , 0.01004454,\n",
       "        0.00531796, 0.00829199, 0.00740543, 0.01018998, 0.00842769,\n",
       "        0.00723438, 0.01018998, 0.00842769, 0.00723438, 0.01018998,\n",
       "        0.00883217, 0.00711002, 0.01018998, 0.00698449, 0.00747442,\n",
       "        0.01018998, 0.00698449, 0.00747442, 0.01018998, 0.00698449,\n",
       "        0.00747442, 0.01017125, 0.00816998, 0.00855319, 0.01017125,\n",
       "        0.00816998, 0.00855319, 0.01017125, 0.00816998, 0.00855319,\n",
       "        0.0066427 , 0.00579598, 0.00780621, 0.00590816, 0.00908994,\n",
       "        0.00553992, 0.00529743, 0.00677729, 0.00712237, 0.00605752,\n",
       "        0.00884158, 0.00957941, 0.00624973, 0.00803881, 0.00873424,\n",
       "        0.00624197, 0.0099603 , 0.0089621 , 0.00436857, 0.00902512,\n",
       "        0.00490209, 0.00432185, 0.00940757, 0.00467029, 0.00432185,\n",
       "        0.00845603, 0.00467029, 0.00927319, 0.00910732, 0.00781644,\n",
       "        0.01196314, 0.00997954, 0.00827511, 0.00768276, 0.00754244,\n",
       "        0.00989527, 0.00915557, 0.0086504 , 0.01030486, 0.01014234,\n",
       "        0.01178231, 0.00901209, 0.00776561, 0.00941705, 0.00835272,\n",
       "        0.00723895, 0.00695744, 0.00656106, 0.00654623, 0.00765082,\n",
       "        0.00665345, 0.00687876, 0.00674998, 0.00742072, 0.00799667,\n",
       "        0.00716615, 0.00995494, 0.00699994, 0.00839935, 0.00764583,\n",
       "        0.00897085, 0.0116539 , 0.00787183, 0.008863  , 0.00989695,\n",
       "        0.00695783, 0.00719698, 0.00975824, 0.01175292, 0.00613114,\n",
       "        0.00971099, 0.00717369, 0.00926461, 0.00840411, 0.00936311,\n",
       "        0.00567276, 0.00685008, 0.01035169, 0.00485326, 0.0063415 ,\n",
       "        0.01004913]),\n",
       " 'rank_test_precision': array([150,  20,  15, 150,  20,  15, 150,  34,  49, 150,  37,  52, 150,\n",
       "         37,  52, 150,  37,  52, 143,  43,  27, 143,  43,  27, 143,  43,\n",
       "         27,   1,  75, 102,   4,  78,  97,  25,  71,  81,  14,  74,  91,\n",
       "         12,  69, 101,  33,  76,  92,   6,  58,  63,   6,  36,  64,   2,\n",
       "         26,  60, 110, 149, 164, 106, 172, 180, 105, 131, 175,  85, 123,\n",
       "        181,  99, 127, 171,  90, 129, 130,  86, 104, 135,  77,  89, 136,\n",
       "         93, 103, 132, 187, 186, 190, 179, 202, 215, 138, 210, 197, 139,\n",
       "        192, 213, 140, 188, 206, 168, 191, 207, 119, 176, 216, 112, 142,\n",
       "        199, 121, 166, 203, 150,  20,  15, 150,  20,  15, 150,  34,  49,\n",
       "        150,  37,  52, 150,  37,  52, 150,  37,  52, 143,  43,  27, 143,\n",
       "         43,  27, 143,  43,  27,  19,  72, 114,  10,  79, 115,  24,  70,\n",
       "         82,   5,  68,  87,  13,  73,  96,  11,  67,  95,   2,  58,  62,\n",
       "          6,  51,  64,   6,  61,  64, 111, 134, 177, 109, 126, 182, 118,\n",
       "        125, 200,  98, 122, 184,  88, 124, 173,  94, 120, 183,  80, 116,\n",
       "        141,  84, 100, 137,  83, 107, 128, 178, 205, 209, 194, 212, 204,\n",
       "        162, 195, 201, 167, 185, 214, 133, 163, 196, 165, 193, 189, 113,\n",
       "        174, 208, 117, 169, 198, 108, 170, 211]),\n",
       " 'split0_test_recall': array([0.72825024, 0.67204301, 0.67057674, 0.72825024, 0.67204301,\n",
       "        0.67057674, 0.72825024, 0.67204301, 0.67253177, 0.72825024,\n",
       "        0.67644184, 0.67302053, 0.72825024, 0.67644184, 0.67302053,\n",
       "        0.72825024, 0.67644184, 0.67302053, 0.72825024, 0.67302053,\n",
       "        0.67155425, 0.72825024, 0.67302053, 0.67155425, 0.72825024,\n",
       "        0.67302053, 0.67155425, 0.69403715, 0.66031281, 0.62316716,\n",
       "        0.69501466, 0.65493646, 0.61730205, 0.69403715, 0.64662757,\n",
       "        0.63147605, 0.69648094, 0.65982405, 0.63929619, 0.69501466,\n",
       "        0.65933529, 0.63587488, 0.69648094, 0.66373412, 0.63929619,\n",
       "        0.69990225, 0.66373412, 0.63929619, 0.69990225, 0.67106549,\n",
       "        0.63391984, 0.69990225, 0.67106549, 0.63734115, 0.6627566 ,\n",
       "        0.59188661, 0.58504399, 0.65786901, 0.58553275, 0.58504399,\n",
       "        0.65591398, 0.59530792, 0.58797654, 0.6627566 , 0.60117302,\n",
       "        0.58553275, 0.66373412, 0.60606061, 0.57771261, 0.6686217 ,\n",
       "        0.59872923, 0.58651026, 0.66813294, 0.62512219, 0.59139785,\n",
       "        0.67302053, 0.61583578, 0.58406647, 0.66568915, 0.61779081,\n",
       "        0.59824047, 0.60703812, 0.58113392, 0.58504399, 0.6143695 ,\n",
       "        0.5801564 , 0.57722385, 0.61388074, 0.56402737, 0.58211144,\n",
       "        0.6226784 , 0.58113392, 0.58993157, 0.60948192, 0.59579668,\n",
       "        0.59139785, 0.62414467, 0.59090909, 0.57966764, 0.63098729,\n",
       "        0.59237537, 0.58406647, 0.6285435 , 0.58797654, 0.58308895,\n",
       "        0.63000978, 0.59042033, 0.58504399, 0.72825024, 0.67204301,\n",
       "        0.67057674, 0.72825024, 0.67204301, 0.67057674, 0.72825024,\n",
       "        0.67204301, 0.67253177, 0.72825024, 0.67644184, 0.67302053,\n",
       "        0.72825024, 0.67644184, 0.67302053, 0.72825024, 0.67644184,\n",
       "        0.67302053, 0.72825024, 0.67302053, 0.67155425, 0.72825024,\n",
       "        0.67302053, 0.67155425, 0.72825024, 0.67302053, 0.67155425,\n",
       "        0.69208211, 0.65347019, 0.62170088, 0.69403715, 0.64907136,\n",
       "        0.62414467, 0.69403715, 0.65738025, 0.62463343, 0.69208211,\n",
       "        0.65933529, 0.63929619, 0.69208211, 0.65982405, 0.63196481,\n",
       "        0.69257087, 0.65982405, 0.63929619, 0.69990225, 0.66373412,\n",
       "        0.63929619, 0.69990225, 0.67057674, 0.63391984, 0.69990225,\n",
       "        0.66373412, 0.63391984, 0.67057674, 0.60606061, 0.58651026,\n",
       "        0.66373412, 0.60117302, 0.58162268, 0.65738025, 0.60361681,\n",
       "        0.57673509, 0.66813294, 0.60068426, 0.58895406, 0.66520039,\n",
       "        0.61143695, 0.5943304 , 0.66324536, 0.61045943, 0.57966764,\n",
       "        0.66666667, 0.62072336, 0.59090909, 0.66813294, 0.61974585,\n",
       "        0.58895406, 0.67008798, 0.61388074, 0.5943304 , 0.6085044 ,\n",
       "        0.58064516, 0.57917889, 0.61485826, 0.58406647, 0.58993157,\n",
       "        0.61290323, 0.58553275, 0.57722385, 0.62512219, 0.58699902,\n",
       "        0.57722385, 0.62756598, 0.5884653 , 0.59286413, 0.61534702,\n",
       "        0.59139785, 0.5742913 , 0.63734115, 0.5884653 , 0.58211144,\n",
       "        0.63196481, 0.59726295, 0.58211144, 0.6344086 , 0.60361681,\n",
       "        0.59286413]),\n",
       " 'split1_test_recall': array([0.69095355, 0.6400978 , 0.64352078, 0.69095355, 0.6400978 ,\n",
       "        0.64352078, 0.69095355, 0.64596577, 0.64156479, 0.69095355,\n",
       "        0.64694377, 0.64156479, 0.69095355, 0.64694377, 0.64156479,\n",
       "        0.69095355, 0.64694377, 0.64156479, 0.69144254, 0.64352078,\n",
       "        0.64743276, 0.69144254, 0.64352078, 0.64743276, 0.69144254,\n",
       "        0.64352078, 0.64743276, 0.6606357 , 0.62591687, 0.60977995,\n",
       "        0.6596577 , 0.62640587, 0.600489  , 0.6596577 , 0.63569682,\n",
       "        0.61173594, 0.6606357 , 0.62542787, 0.61320293, 0.66112469,\n",
       "        0.62542787, 0.61320293, 0.6606357 , 0.62542787, 0.61173594,\n",
       "        0.66161369, 0.63276284, 0.62200489, 0.66161369, 0.63276284,\n",
       "        0.62200489, 0.66161369, 0.63276284, 0.62200489, 0.63325183,\n",
       "        0.58484108, 0.56821516, 0.63227384, 0.57114914, 0.57408313,\n",
       "        0.63667482, 0.58973105, 0.56723716, 0.64792176, 0.58239609,\n",
       "        0.57848411, 0.63618582, 0.59217604, 0.57603912, 0.6400978 ,\n",
       "        0.58777506, 0.5799511 , 0.65085575, 0.60293399, 0.58533007,\n",
       "        0.65378973, 0.60635697, 0.58337408, 0.64889976, 0.60929095,\n",
       "        0.58386308, 0.5804401 , 0.57066015, 0.55892421, 0.58386308,\n",
       "        0.5599022 , 0.56479218, 0.58630807, 0.56821516, 0.57261614,\n",
       "        0.59657702, 0.56772616, 0.56381418, 0.60391198, 0.57408313,\n",
       "        0.56185819, 0.61222494, 0.57555012, 0.57212714, 0.61760391,\n",
       "        0.58386308, 0.57017115, 0.62249389, 0.58141809, 0.56723716,\n",
       "        0.62200489, 0.58337408, 0.56870416, 0.69095355, 0.6400978 ,\n",
       "        0.64352078, 0.69095355, 0.6400978 , 0.64352078, 0.69095355,\n",
       "        0.64596577, 0.64156479, 0.69095355, 0.64694377, 0.64156479,\n",
       "        0.69095355, 0.64694377, 0.64156479, 0.69095355, 0.64694377,\n",
       "        0.64156479, 0.69144254, 0.64352078, 0.64743276, 0.69144254,\n",
       "        0.64352078, 0.64743276, 0.69144254, 0.64352078, 0.64743276,\n",
       "        0.6606357 , 0.62738386, 0.61026895, 0.6596577 , 0.62542787,\n",
       "        0.59119804, 0.6606357 , 0.62689487, 0.60831296, 0.65819071,\n",
       "        0.6400978 , 0.61320293, 0.66112469, 0.6400978 , 0.61320293,\n",
       "        0.65819071, 0.62542787, 0.61418093, 0.66161369, 0.63276284,\n",
       "        0.62200489, 0.66161369, 0.63276284, 0.62200489, 0.66161369,\n",
       "        0.63276284, 0.62200489, 0.63080685, 0.57799511, 0.56625917,\n",
       "        0.62982885, 0.5804401 , 0.57066015, 0.63520782, 0.58924205,\n",
       "        0.56625917, 0.63471883, 0.58288509, 0.56870416, 0.64547677,\n",
       "        0.59559902, 0.57652812, 0.62982885, 0.58973105, 0.57359413,\n",
       "        0.65525672, 0.60929095, 0.58141809, 0.64938875, 0.6       ,\n",
       "        0.59070905, 0.65574572, 0.60195599, 0.57555012, 0.5809291 ,\n",
       "        0.56821516, 0.56674817, 0.58141809, 0.56821516, 0.57114914,\n",
       "        0.58484108, 0.55647922, 0.56479218, 0.599022  , 0.57897311,\n",
       "        0.56919315, 0.60195599, 0.57163814, 0.56234719, 0.6       ,\n",
       "        0.57457213, 0.57017115, 0.61124694, 0.5799511 , 0.56283619,\n",
       "        0.6200489 , 0.58288509, 0.56870416, 0.62738386, 0.59168704,\n",
       "        0.56821516]),\n",
       " 'split2_test_recall': array([0.71882641, 0.68264059, 0.67383863, 0.71882641, 0.68264059,\n",
       "        0.67383863, 0.71882641, 0.68312958, 0.67286064, 0.71882641,\n",
       "        0.6801956 , 0.67432763, 0.71882641, 0.6801956 , 0.67432763,\n",
       "        0.71882641, 0.6801956 , 0.67432763, 0.71882641, 0.68704156,\n",
       "        0.67481663, 0.71882641, 0.68704156, 0.67481663, 0.71882641,\n",
       "        0.68704156, 0.67481663, 0.69046455, 0.64694377, 0.62738386,\n",
       "        0.69290954, 0.64889976, 0.62200489, 0.68899756, 0.64645477,\n",
       "        0.62933985, 0.68899756, 0.65134474, 0.62200489, 0.7007335 ,\n",
       "        0.65281174, 0.6190709 , 0.68459658, 0.65134474, 0.62493888,\n",
       "        0.69095355, 0.65721271, 0.63178484, 0.69095355, 0.65281174,\n",
       "        0.62738386, 0.69095355, 0.65721271, 0.63178484, 0.64547677,\n",
       "        0.5799511 , 0.58288509, 0.64596577, 0.58826406, 0.58190709,\n",
       "        0.64547677, 0.599511  , 0.5799511 , 0.66210269, 0.60146699,\n",
       "        0.5809291 , 0.65476773, 0.60537897, 0.58581907, 0.65183374,\n",
       "        0.60586797, 0.59168704, 0.66161369, 0.6195599 , 0.59511002,\n",
       "        0.66992665, 0.61564792, 0.57897311, 0.66894866, 0.62396088,\n",
       "        0.59853301, 0.60537897, 0.58435208, 0.5804401 , 0.59315403,\n",
       "        0.57750611, 0.57212714, 0.6200489 , 0.5799511 , 0.58484108,\n",
       "        0.63129584, 0.5809291 , 0.57603912, 0.61369193, 0.59217604,\n",
       "        0.58777506, 0.6200489 , 0.5794621 , 0.57408313, 0.63031785,\n",
       "        0.59706601, 0.57408313, 0.63080685, 0.59657702, 0.58239609,\n",
       "        0.63520782, 0.60146699, 0.58484108, 0.71882641, 0.68264059,\n",
       "        0.67383863, 0.71882641, 0.68264059, 0.67383863, 0.71882641,\n",
       "        0.68312958, 0.67286064, 0.71882641, 0.6801956 , 0.67432763,\n",
       "        0.71882641, 0.6801956 , 0.67432763, 0.71882641, 0.6801956 ,\n",
       "        0.67432763, 0.71882641, 0.68704156, 0.67481663, 0.71882641,\n",
       "        0.68704156, 0.67481663, 0.71882641, 0.68704156, 0.67481663,\n",
       "        0.69242054, 0.6405868 , 0.61271394, 0.68753056, 0.64889976,\n",
       "        0.61466993, 0.68899756, 0.64694377, 0.62347188, 0.69046455,\n",
       "        0.65085575, 0.62493888, 0.68899756, 0.64352078, 0.62444988,\n",
       "        0.68997555, 0.65378973, 0.63080685, 0.69095355, 0.65721271,\n",
       "        0.62738386, 0.69095355, 0.65281174, 0.62738386, 0.69095355,\n",
       "        0.65281174, 0.62738386, 0.64938875, 0.599511  , 0.57897311,\n",
       "        0.6596577 , 0.60293399, 0.57897311, 0.65183374, 0.60440098,\n",
       "        0.57457213, 0.64743276, 0.600489  , 0.58679707, 0.65134474,\n",
       "        0.59755501, 0.58141809, 0.65672372, 0.60195599, 0.58581907,\n",
       "        0.66308068, 0.61369193, 0.60391198, 0.66503667, 0.61858191,\n",
       "        0.59119804, 0.66992665, 0.62151589, 0.59608802, 0.60293399,\n",
       "        0.57848411, 0.58141809, 0.58875306, 0.57163814, 0.57652812,\n",
       "        0.61809291, 0.5794621 , 0.56919315, 0.61809291, 0.58435208,\n",
       "        0.57555012, 0.62200489, 0.59119804, 0.5794621 , 0.62200489,\n",
       "        0.59608802, 0.58581907, 0.63325183, 0.599511  , 0.57359413,\n",
       "        0.63667482, 0.60146699, 0.57261614, 0.63129584, 0.59706601,\n",
       "        0.58533007]),\n",
       " 'split3_test_recall': array([0.70332356, 0.65835777, 0.64565005, 0.70332356, 0.65835777,\n",
       "        0.64565005, 0.70332356, 0.65249267, 0.64711632, 0.70332356,\n",
       "        0.65395894, 0.64222874, 0.70332356, 0.65395894, 0.64222874,\n",
       "        0.70332356, 0.65395894, 0.64222874, 0.70332356, 0.65151515,\n",
       "        0.64516129, 0.70332356, 0.65151515, 0.64516129, 0.70332356,\n",
       "        0.65151515, 0.64516129, 0.67302053, 0.63880743, 0.62414467,\n",
       "        0.67644184, 0.64809384, 0.62952102, 0.67350929, 0.63782991,\n",
       "        0.62463343, 0.67790811, 0.64173998, 0.62952102, 0.67790811,\n",
       "        0.64173998, 0.62952102, 0.67790811, 0.6427175 , 0.62903226,\n",
       "        0.68377322, 0.65542522, 0.64418377, 0.68377322, 0.65542522,\n",
       "        0.64418377, 0.68377322, 0.65542522, 0.64418377, 0.63734115,\n",
       "        0.59090909, 0.5884653 , 0.64613881, 0.6026393 , 0.58895406,\n",
       "        0.65004888, 0.61339198, 0.59579668, 0.6568915 , 0.60703812,\n",
       "        0.58993157, 0.65395894, 0.62316716, 0.60508309, 0.65004888,\n",
       "        0.61241447, 0.59530792, 0.66520039, 0.62316716, 0.60215054,\n",
       "        0.65835777, 0.63391984, 0.6026393 , 0.6627566 , 0.62170088,\n",
       "        0.61192571, 0.61681329, 0.5884653 , 0.59188661, 0.61681329,\n",
       "        0.58699902, 0.58211144, 0.61730205, 0.59530792, 0.59921799,\n",
       "        0.61339198, 0.58699902, 0.58553275, 0.6143695 , 0.58553275,\n",
       "        0.58797654, 0.60801564, 0.58113392, 0.58797654, 0.62561095,\n",
       "        0.60361681, 0.58553275, 0.63343109, 0.60215054, 0.58699902,\n",
       "        0.62561095, 0.60068426, 0.59090909, 0.70332356, 0.65835777,\n",
       "        0.64565005, 0.70332356, 0.65835777, 0.64565005, 0.70332356,\n",
       "        0.65249267, 0.64711632, 0.70332356, 0.65395894, 0.64222874,\n",
       "        0.70332356, 0.65395894, 0.64222874, 0.70332356, 0.65395894,\n",
       "        0.64222874, 0.70332356, 0.65151515, 0.64516129, 0.70332356,\n",
       "        0.65151515, 0.64516129, 0.70332356, 0.65151515, 0.64516129,\n",
       "        0.66911046, 0.64369501, 0.61925709, 0.67302053, 0.63929619,\n",
       "        0.6202346 , 0.67595308, 0.64565005, 0.6285435 , 0.67790811,\n",
       "        0.64173998, 0.6285435 , 0.67790811, 0.6427175 , 0.62903226,\n",
       "        0.67790811, 0.64173998, 0.62903226, 0.68377322, 0.65542522,\n",
       "        0.64418377, 0.68377322, 0.65542522, 0.64418377, 0.68377322,\n",
       "        0.65542522, 0.64418377, 0.65102639, 0.60801564, 0.60508309,\n",
       "        0.64467253, 0.60899316, 0.59286413, 0.64809384, 0.60948192,\n",
       "        0.59628543, 0.64613881, 0.61192571, 0.59775171, 0.64613881,\n",
       "        0.6085044 , 0.59530792, 0.6568915 , 0.61485826, 0.58895406,\n",
       "        0.66422287, 0.62561095, 0.60801564, 0.66226784, 0.63196481,\n",
       "        0.59921799, 0.65933529, 0.62121212, 0.60703812, 0.60899316,\n",
       "        0.59530792, 0.57771261, 0.61143695, 0.59824047, 0.58308895,\n",
       "        0.61779081, 0.59775171, 0.58993157, 0.60410557, 0.59481916,\n",
       "        0.59042033, 0.60606061, 0.58406647, 0.57820137, 0.60508309,\n",
       "        0.5742913 , 0.58406647, 0.63049853, 0.60508309, 0.59384164,\n",
       "        0.6285435 , 0.60215054, 0.59188661, 0.6285435 , 0.60117302,\n",
       "        0.58797654]),\n",
       " 'split4_test_recall': array([0.71945259, 0.67546432, 0.66568915, 0.71945259, 0.67546432,\n",
       "        0.66568915, 0.71945259, 0.67546432, 0.65933529, 0.71945259,\n",
       "        0.66617791, 0.66129032, 0.71945259, 0.66617791, 0.66129032,\n",
       "        0.71945259, 0.66617791, 0.66129032, 0.71945259, 0.67399804,\n",
       "        0.65884653, 0.71945259, 0.67399804, 0.65884653, 0.71945259,\n",
       "        0.67399804, 0.65884653, 0.67741935, 0.64907136, 0.61779081,\n",
       "        0.68523949, 0.65053763, 0.62707722, 0.67546432, 0.65982405,\n",
       "        0.63782991, 0.67741935, 0.65053763, 0.62365591, 0.67741935,\n",
       "        0.64516129, 0.62658847, 0.67741935, 0.65102639, 0.62365591,\n",
       "        0.68035191, 0.6568915 , 0.64125122, 0.68035191, 0.6568915 ,\n",
       "        0.64125122, 0.68035191, 0.6568915 , 0.64125122, 0.63880743,\n",
       "        0.59824047, 0.59237537, 0.64076246, 0.59628543, 0.58993157,\n",
       "        0.63538612, 0.60410557, 0.5943304 , 0.63636364, 0.60752688,\n",
       "        0.6001955 , 0.63685239, 0.60459433, 0.59824047, 0.64125122,\n",
       "        0.60752688, 0.6026393 , 0.63929619, 0.61925709, 0.59921799,\n",
       "        0.64173998, 0.61779081, 0.60410557, 0.63734115, 0.61974585,\n",
       "        0.61192571, 0.60508309, 0.5943304 , 0.58406647, 0.61094819,\n",
       "        0.59090909, 0.57869013, 0.61094819, 0.58895406, 0.58993157,\n",
       "        0.60508309, 0.59726295, 0.58553275, 0.61388074, 0.58993157,\n",
       "        0.59042033, 0.60410557, 0.5884653 , 0.58748778, 0.61534702,\n",
       "        0.59286413, 0.58308895, 0.61388074, 0.60215054, 0.59042033,\n",
       "        0.6143695 , 0.59921799, 0.59481916, 0.71945259, 0.67546432,\n",
       "        0.66568915, 0.71945259, 0.67546432, 0.66568915, 0.71945259,\n",
       "        0.67546432, 0.65933529, 0.71945259, 0.66617791, 0.66129032,\n",
       "        0.71945259, 0.66617791, 0.66129032, 0.71945259, 0.66617791,\n",
       "        0.66129032, 0.71945259, 0.67399804, 0.65884653, 0.71945259,\n",
       "        0.67399804, 0.65884653, 0.71945259, 0.67399804, 0.65884653,\n",
       "        0.67741935, 0.64076246, 0.62463343, 0.67741935, 0.64956012,\n",
       "        0.62756598, 0.67546432, 0.65884653, 0.63147605, 0.67741935,\n",
       "        0.64516129, 0.62316716, 0.67741935, 0.65102639, 0.62658847,\n",
       "        0.67741935, 0.65102639, 0.62658847, 0.68035191, 0.6568915 ,\n",
       "        0.64125122, 0.68035191, 0.6568915 , 0.64125122, 0.68035191,\n",
       "        0.6568915 , 0.64125122, 0.63782991, 0.59237537, 0.59530792,\n",
       "        0.63978495, 0.6001955 , 0.58308895, 0.63147605, 0.60508309,\n",
       "        0.59188661, 0.64076246, 0.60606061, 0.59237537, 0.64222874,\n",
       "        0.60410557, 0.5943304 , 0.63294233, 0.60312805, 0.6026393 ,\n",
       "        0.64662757, 0.61045943, 0.6001955 , 0.64565005, 0.61339198,\n",
       "        0.6085044 , 0.64467253, 0.61681329, 0.60606061, 0.61241447,\n",
       "        0.58895406, 0.57575758, 0.60997067, 0.5826002 , 0.57526882,\n",
       "        0.61094819, 0.58748778, 0.5826002 , 0.60801564, 0.58211144,\n",
       "        0.58406647, 0.6143695 , 0.59286413, 0.59139785, 0.60899316,\n",
       "        0.59677419, 0.58993157, 0.61974585, 0.59481916, 0.59237537,\n",
       "        0.62170088, 0.58993157, 0.59677419, 0.61876833, 0.59579668,\n",
       "        0.59335288]),\n",
       " 'mean_test_recall': array([0.71216127, 0.6657207 , 0.65985507, 0.71216127, 0.6657207 ,\n",
       "        0.65985507, 0.71216127, 0.66581907, 0.65868176, 0.71216127,\n",
       "        0.66474361, 0.6584864 , 0.71216127, 0.66474361, 0.6584864 ,\n",
       "        0.71216127, 0.66474361, 0.6584864 , 0.71225907, 0.66581921,\n",
       "        0.65956229, 0.71225907, 0.66581921, 0.65956229, 0.71225907,\n",
       "        0.66581921, 0.65956229, 0.67911545, 0.64421045, 0.62045329,\n",
       "        0.68185265, 0.64577471, 0.61927884, 0.6783332 , 0.64528662,\n",
       "        0.62700304, 0.68028833, 0.64577486, 0.62553619, 0.68244006,\n",
       "        0.64489523, 0.62485164, 0.67940814, 0.64685012, 0.62573184,\n",
       "        0.68331892, 0.65320528, 0.63570418, 0.68331892, 0.65379136,\n",
       "        0.63374872, 0.68331892, 0.65467155, 0.63531318, 0.64352676,\n",
       "        0.58916567, 0.58339698, 0.64460198, 0.58877414, 0.58398397,\n",
       "        0.64470011, 0.60040951, 0.58505838, 0.65320724, 0.59992022,\n",
       "        0.58701461, 0.6490998 , 0.60627542, 0.58857887, 0.65037067,\n",
       "        0.60246272, 0.59121912, 0.65701979, 0.61800806, 0.59464129,\n",
       "        0.65936693, 0.61791026, 0.59063171, 0.65672706, 0.61849787,\n",
       "        0.60089759, 0.60295072, 0.58378837, 0.58007227, 0.60382962,\n",
       "        0.57909457, 0.57498895, 0.60969759, 0.57929112, 0.58574364,\n",
       "        0.61380527, 0.58281023, 0.58017007, 0.61106721, 0.58750403,\n",
       "        0.58388559, 0.61370794, 0.58310411, 0.58026845, 0.6239734 ,\n",
       "        0.59395708, 0.57938849, 0.62583121, 0.59405454, 0.58202831,\n",
       "        0.62544059, 0.59503273, 0.58486349, 0.71216127, 0.6657207 ,\n",
       "        0.65985507, 0.71216127, 0.6657207 , 0.65985507, 0.71216127,\n",
       "        0.66581907, 0.65868176, 0.71216127, 0.66474361, 0.6584864 ,\n",
       "        0.71216127, 0.66474361, 0.6584864 , 0.71216127, 0.66474361,\n",
       "        0.6584864 , 0.71225907, 0.66581921, 0.65956229, 0.71225907,\n",
       "        0.66581921, 0.65956229, 0.71225907, 0.66581921, 0.65956229,\n",
       "        0.67833363, 0.64117966, 0.61771486, 0.67833306, 0.64245106,\n",
       "        0.61556265, 0.67901756, 0.64714309, 0.62328756, 0.67921297,\n",
       "        0.64743802, 0.62582973, 0.67950637, 0.6474373 , 0.62504767,\n",
       "        0.67921292, 0.6463616 , 0.62798094, 0.68331892, 0.65320528,\n",
       "        0.63482399, 0.68331892, 0.6536936 , 0.63374872, 0.68331892,\n",
       "        0.65232508, 0.63374872, 0.64792573, 0.59679155, 0.58642671,\n",
       "        0.64753563, 0.59874715, 0.5814418 , 0.64479834, 0.60236497,\n",
       "        0.58114769, 0.64743716, 0.60040893, 0.58691647, 0.65007789,\n",
       "        0.60344019, 0.58838299, 0.64792635, 0.60402656, 0.58613484,\n",
       "        0.6591709 , 0.61595533, 0.59689006, 0.65809525, 0.61673691,\n",
       "        0.59571671, 0.65995363, 0.61507561, 0.59581345, 0.60275502,\n",
       "        0.58232128, 0.57616307, 0.60128741, 0.58095209, 0.57919332,\n",
       "        0.60891524, 0.58134271, 0.57674819, 0.61087166, 0.58545096,\n",
       "        0.57929079, 0.61439139, 0.58564642, 0.58085453, 0.61028563,\n",
       "        0.5866247 , 0.58085591, 0.62641686, 0.59356593, 0.58095175,\n",
       "        0.62778658, 0.59473943, 0.58241851, 0.62808003, 0.59786791,\n",
       "        0.58554776]),\n",
       " 'std_test_recall': array([0.01329899, 0.01504618, 0.01275243, 0.01329899, 0.01504618,\n",
       "        0.01275243, 0.01329899, 0.01416452, 0.01280656, 0.01329899,\n",
       "        0.01273431, 0.01428776, 0.01329899, 0.01273431, 0.01428776,\n",
       "        0.01329899, 0.01273431, 0.01428776, 0.01314356, 0.01594344,\n",
       "        0.01209569, 0.01314356, 0.01594344, 0.01209569, 0.01314356,\n",
       "        0.01594344, 0.01209569, 0.01210773, 0.01143882, 0.00616495,\n",
       "        0.01287522, 0.00996915, 0.01029674, 0.0121706 , 0.0085096 ,\n",
       "        0.00873372, 0.0121505 , 0.01167362, 0.00864096, 0.01409157,\n",
       "        0.01149079, 0.0079428 , 0.01163624, 0.01263886, 0.00889615,\n",
       "        0.01275477, 0.01061438, 0.00798257, 0.01275477, 0.01227872,\n",
       "        0.00829019, 0.01275477, 0.01233456, 0.00784373, 0.01038939,\n",
       "        0.00626746, 0.00824332, 0.0083302 , 0.01067773, 0.00571908,\n",
       "        0.00782457, 0.00803827, 0.01052119, 0.00995526, 0.0091606 ,\n",
       "        0.00767129, 0.01083208, 0.00987724, 0.01139011, 0.01023758,\n",
       "        0.00855506, 0.00770064, 0.01061744, 0.00785396, 0.00591225,\n",
       "        0.01132044, 0.00893556, 0.01055865, 0.01185851, 0.00503842,\n",
       "        0.0104505 , 0.01205031, 0.0079085 , 0.0112038 , 0.01298437,\n",
       "        0.01071505, 0.0060264 , 0.01209223, 0.0118828 , 0.00877993,\n",
       "        0.01231026, 0.00959484, 0.0093529 , 0.00398549, 0.00748993,\n",
       "        0.01110141, 0.00742887, 0.00572483, 0.00657926, 0.00643604,\n",
       "        0.0064585 , 0.00610631, 0.00698316, 0.00817405, 0.00793942,\n",
       "        0.00708065, 0.0070435 , 0.00890867, 0.01329899, 0.01504618,\n",
       "        0.01275243, 0.01329899, 0.01504618, 0.01275243, 0.01329899,\n",
       "        0.01416452, 0.01280656, 0.01329899, 0.01273431, 0.01428776,\n",
       "        0.01329899, 0.01273431, 0.01428776, 0.01329899, 0.01273431,\n",
       "        0.01428776, 0.01314356, 0.01594344, 0.01209569, 0.01314356,\n",
       "        0.01594344, 0.01209569, 0.01314356, 0.01594344, 0.01209569,\n",
       "        0.01254258, 0.00834546, 0.0054145 , 0.01190831, 0.00933483,\n",
       "        0.01291502, 0.01170553, 0.01143704, 0.0080095 , 0.01215786,\n",
       "        0.00699651, 0.00843835, 0.01089062, 0.00718049, 0.00643044,\n",
       "        0.01217474, 0.01198128, 0.00811794, 0.01275477, 0.01061438,\n",
       "        0.00858604, 0.01275477, 0.01214199, 0.00829019, 0.01275477,\n",
       "        0.01042638, 0.00829019, 0.01356322, 0.01088209, 0.01333589,\n",
       "        0.01257884, 0.0096503 , 0.00714918, 0.00988052, 0.00686968,\n",
       "        0.01121475, 0.01128103, 0.00971334, 0.0098291 , 0.00810667,\n",
       "        0.00610174, 0.00784533, 0.01374394, 0.00858095, 0.00979325,\n",
       "        0.00734372, 0.00625631, 0.00958296, 0.00891106, 0.01035045,\n",
       "        0.0073077 , 0.00952646, 0.0071513 , 0.01134791, 0.01132853,\n",
       "        0.00926458, 0.00505799, 0.0135239 , 0.01058568, 0.00659848,\n",
       "        0.01234996, 0.01375721, 0.00903658, 0.00948235, 0.00537554,\n",
       "        0.00730617, 0.00954544, 0.00761039, 0.01101718, 0.00771349,\n",
       "        0.01012647, 0.00741035, 0.00956395, 0.00872857, 0.01166449,\n",
       "        0.00622798, 0.00735111, 0.01077028, 0.00524975, 0.00417396,\n",
       "        0.00917403]),\n",
       " 'rank_test_recall': array([  7,  45,  56,   7,  45,  56,   7,  43,  68,   7,  49,  70,   7,\n",
       "         49,  70,   7,  49,  70,   1,  37,  60,   1,  37,  60,   1,  37,\n",
       "         60,  32, 105, 129,  26,  99, 130,  35, 100, 118,  27,  98, 123,\n",
       "         25, 101, 126,  29,  96, 122,  19,  83, 109,  19,  80, 112,  19,\n",
       "         79, 110, 106, 174, 193, 104, 175, 190, 103, 157, 188,  82, 159,\n",
       "        179,  88, 147, 176,  86, 153, 172,  77, 132, 168,  66, 133, 173,\n",
       "         78, 131, 156, 151, 192, 208, 149, 213, 216, 145, 210, 184, 140,\n",
       "        195, 207, 142, 178, 191, 141, 194, 206, 127, 170, 209, 120, 169,\n",
       "        198, 124, 166, 189,   7,  45,  56,   7,  45,  56,   7,  43,  68,\n",
       "          7,  49,  70,   7,  49,  70,   7,  49,  70,   1,  37,  60,   1,\n",
       "         37,  60,   1,  37,  60,  34, 108, 134,  36, 107, 137,  33,  95,\n",
       "        128,  30,  92, 121,  28,  93, 125,  31,  97, 116,  19,  83, 111,\n",
       "         19,  81, 112,  19,  85, 112,  90, 163, 182,  91, 160, 199, 102,\n",
       "        154, 201,  94, 158, 180,  87, 150, 177,  89, 148, 183,  67, 136,\n",
       "        162,  76, 135, 165,  55, 138, 164, 152, 197, 215, 155, 202, 212,\n",
       "        146, 200, 214, 143, 187, 211, 139, 185, 205, 144, 181, 204, 119,\n",
       "        171, 203, 117, 167, 196, 115, 161, 186]),\n",
       " 'split0_test_accuracy': array([0.61045943, 0.62414467, 0.62878788, 0.61045943, 0.62414467,\n",
       "        0.62878788, 0.61045943, 0.62414467, 0.62829912, 0.61045943,\n",
       "        0.62561095, 0.6273216 , 0.61045943, 0.62561095, 0.6273216 ,\n",
       "        0.61045943, 0.62561095, 0.6273216 , 0.61021505, 0.62243402,\n",
       "        0.62512219, 0.61021505, 0.62243402, 0.62512219, 0.61021505,\n",
       "        0.62243402, 0.62512219, 0.63245357, 0.6297654 , 0.61779081,\n",
       "        0.63147605, 0.6226784 , 0.61314761, 0.63123167, 0.62487781,\n",
       "        0.62218964, 0.63220919, 0.63000978, 0.62609971, 0.63196481,\n",
       "        0.63049853, 0.6214565 , 0.63220919, 0.62609971, 0.62609971,\n",
       "        0.63123167, 0.62585533, 0.6202346 , 0.63123167, 0.63514174,\n",
       "        0.61656891, 0.63343109, 0.63514174, 0.62096774, 0.62194526,\n",
       "        0.60092864, 0.6001955 , 0.62341153, 0.59530792, 0.59946237,\n",
       "        0.61827957, 0.60386119, 0.60043988, 0.62634409, 0.61339198,\n",
       "        0.60117302, 0.62414467, 0.60948192, 0.59335288, 0.62927664,\n",
       "        0.60606061, 0.6014174 , 0.62341153, 0.61705767, 0.60752688,\n",
       "        0.62634409, 0.61485826, 0.59897361, 0.62414467, 0.61534702,\n",
       "        0.60288368, 0.5943304 , 0.59677419, 0.59799609, 0.60410557,\n",
       "        0.59579668, 0.59237537, 0.60410557, 0.58455523, 0.59457478,\n",
       "        0.60801564, 0.59970674, 0.59726295, 0.6026393 , 0.60508309,\n",
       "        0.60239492, 0.60777126, 0.60312805, 0.59995112, 0.61265885,\n",
       "        0.59750733, 0.59750733, 0.61168133, 0.60483871, 0.60043988,\n",
       "        0.61021505, 0.59970674, 0.59848485, 0.61045943, 0.62414467,\n",
       "        0.62878788, 0.61045943, 0.62414467, 0.62878788, 0.61045943,\n",
       "        0.62414467, 0.62829912, 0.61045943, 0.62561095, 0.6273216 ,\n",
       "        0.61045943, 0.62561095, 0.6273216 , 0.61045943, 0.62561095,\n",
       "        0.6273216 , 0.61021505, 0.62243402, 0.62512219, 0.61021505,\n",
       "        0.62243402, 0.62512219, 0.61021505, 0.62243402, 0.62512219,\n",
       "        0.62903226, 0.62561095, 0.61705767, 0.63000978, 0.62438905,\n",
       "        0.61339198, 0.63123167, 0.62390029, 0.61827957, 0.63269795,\n",
       "        0.63049853, 0.62609971, 0.63269795, 0.63000978, 0.62438905,\n",
       "        0.63294233, 0.63000978, 0.62609971, 0.63343109, 0.62585533,\n",
       "        0.6202346 , 0.63123167, 0.63269795, 0.61656891, 0.63123167,\n",
       "        0.62585533, 0.61656891, 0.62634409, 0.61021505, 0.59921799,\n",
       "        0.62487781, 0.60997067, 0.59408602, 0.61999022, 0.6072825 ,\n",
       "        0.5943304 , 0.62927664, 0.61168133, 0.60288368, 0.6297654 ,\n",
       "        0.61852395, 0.60532747, 0.62414467, 0.61461388, 0.59848485,\n",
       "        0.62536657, 0.6155914 , 0.60288368, 0.6226784 , 0.61730205,\n",
       "        0.60117302, 0.62463343, 0.61241447, 0.59995112, 0.60215054,\n",
       "        0.59261975, 0.59506354, 0.59995112, 0.59530792, 0.59750733,\n",
       "        0.6001955 , 0.59872923, 0.59506354, 0.61021505, 0.60288368,\n",
       "        0.59335288, 0.61290323, 0.60581623, 0.60239492, 0.60410557,\n",
       "        0.6026393 , 0.59677419, 0.61852395, 0.59652981, 0.5955523 ,\n",
       "        0.61119257, 0.60312805, 0.60215054, 0.61510264, 0.60288368,\n",
       "        0.59970674]),\n",
       " 'split1_test_accuracy': array([0.61525299, 0.61427524, 0.61525299, 0.61525299, 0.61427524,\n",
       "        0.61525299, 0.61525299, 0.61500856, 0.61231973, 0.61525299,\n",
       "        0.61647519, 0.61256417, 0.61525299, 0.61647519, 0.61256417,\n",
       "        0.61525299, 0.61647519, 0.61256417, 0.61549743, 0.61647519,\n",
       "        0.6140308 , 0.61549743, 0.61647519, 0.6140308 , 0.61549743,\n",
       "        0.61647519, 0.6140308 , 0.6184307 , 0.60229773, 0.59789782,\n",
       "        0.61525299, 0.60303104, 0.59276461, 0.61549743, 0.6084087 ,\n",
       "        0.59863114, 0.61720851, 0.60376436, 0.60083109, 0.61794182,\n",
       "        0.60376436, 0.60180885, 0.61720851, 0.60376436, 0.59887558,\n",
       "        0.61818626, 0.60547543, 0.6096309 , 0.61818626, 0.60547543,\n",
       "        0.6096309 , 0.61818626, 0.60547543, 0.6096309 , 0.60131997,\n",
       "        0.58347592, 0.57907602, 0.59765339, 0.57638719, 0.57736495,\n",
       "        0.60351992, 0.58763139, 0.57418724, 0.60474212, 0.58298704,\n",
       "        0.57858714, 0.60009778, 0.58420924, 0.57858714, 0.60376436,\n",
       "        0.58420924, 0.58274261, 0.60743095, 0.59300904, 0.58323148,\n",
       "        0.6084087 , 0.59887558, 0.58665363, 0.60547543, 0.59618675,\n",
       "        0.58054265, 0.58200929, 0.57760939, 0.57345392, 0.57785383,\n",
       "        0.57100953, 0.57125397, 0.58567587, 0.57369836, 0.57247617,\n",
       "        0.58420924, 0.57345392, 0.56709851, 0.59203129, 0.57369836,\n",
       "        0.56612075, 0.59154241, 0.58200929, 0.57345392, 0.59692007,\n",
       "        0.58298704, 0.57345392, 0.59887558, 0.57858714, 0.57418724,\n",
       "        0.59887558, 0.58152041, 0.57883158, 0.61525299, 0.61427524,\n",
       "        0.61525299, 0.61525299, 0.61427524, 0.61525299, 0.61525299,\n",
       "        0.61500856, 0.61231973, 0.61525299, 0.61647519, 0.61256417,\n",
       "        0.61525299, 0.61647519, 0.61256417, 0.61525299, 0.61647519,\n",
       "        0.61256417, 0.61549743, 0.61647519, 0.6140308 , 0.61549743,\n",
       "        0.61647519, 0.6140308 , 0.61549743, 0.61647519, 0.6140308 ,\n",
       "        0.6184307 , 0.60791982, 0.59789782, 0.61525299, 0.60205329,\n",
       "        0.59667563, 0.61647519, 0.60547543, 0.60327548, 0.61769738,\n",
       "        0.60816426, 0.60083109, 0.61794182, 0.60816426, 0.60205329,\n",
       "        0.61769738, 0.60376436, 0.60180885, 0.61818626, 0.60547543,\n",
       "        0.6096309 , 0.61818626, 0.60547543, 0.6096309 , 0.61818626,\n",
       "        0.60547543, 0.6096309 , 0.59863114, 0.58225373, 0.57760939,\n",
       "        0.5983867 , 0.58225373, 0.57589831, 0.59985334, 0.58665363,\n",
       "        0.57247617, 0.60107553, 0.58860914, 0.57418724, 0.60449768,\n",
       "        0.58714251, 0.57980934, 0.60034221, 0.58665363, 0.57760939,\n",
       "        0.60743095, 0.59569787, 0.58640919, 0.60694207, 0.59423124,\n",
       "        0.5883647 , 0.60865314, 0.59496456, 0.58347592, 0.58054265,\n",
       "        0.57443168, 0.57149841, 0.5795649 , 0.57149841, 0.5783427 ,\n",
       "        0.58054265, 0.56660963, 0.575165  , 0.58738695, 0.57663163,\n",
       "        0.5739428 , 0.59325348, 0.57858714, 0.56929846, 0.58812026,\n",
       "        0.57687607, 0.57883158, 0.59129797, 0.57736495, 0.5739428 ,\n",
       "        0.59643119, 0.5839648 , 0.57858714, 0.60131997, 0.58469812,\n",
       "        0.57369836]),\n",
       " 'split2_test_accuracy': array([0.60889758, 0.62454168, 0.62600831, 0.60889758, 0.62454168,\n",
       "        0.62600831, 0.60889758, 0.62649719, 0.6284527 , 0.60889758,\n",
       "        0.62478612, 0.6284527 , 0.60889758, 0.62478612, 0.6284527 ,\n",
       "        0.60889758, 0.62478612, 0.6284527 , 0.60938646, 0.62625275,\n",
       "        0.62820826, 0.60938646, 0.62625275, 0.62820826, 0.60938646,\n",
       "        0.62625275, 0.62820826, 0.6328526 , 0.61867514, 0.61134197,\n",
       "        0.63774138, 0.62063065, 0.61207529, 0.63236373, 0.62038621,\n",
       "        0.61525299, 0.63358592, 0.6228306 , 0.60816426, 0.63700807,\n",
       "        0.62478612, 0.60889758, 0.63065265, 0.6228306 , 0.61011978,\n",
       "        0.63358592, 0.62894158, 0.61769738, 0.63358592, 0.62503055,\n",
       "        0.61769738, 0.63358592, 0.62698607, 0.61769738, 0.61500856,\n",
       "        0.59423124, 0.59203129, 0.61769738, 0.59618675, 0.59032022,\n",
       "        0.62209729, 0.59985334, 0.59105353, 0.62551943, 0.59936446,\n",
       "        0.58934246, 0.61647519, 0.60009778, 0.59349792, 0.61891958,\n",
       "        0.5996089 , 0.59618675, 0.62087509, 0.60889758, 0.59740895,\n",
       "        0.62796382, 0.60914202, 0.59105353, 0.62478612, 0.61085309,\n",
       "        0.59545343, 0.59863114, 0.5895869 , 0.58763139, 0.59032022,\n",
       "        0.58543143, 0.58029822, 0.6040088 , 0.5883647 , 0.58689807,\n",
       "        0.60743095, 0.58274261, 0.58347592, 0.60229773, 0.59056465,\n",
       "        0.58885358, 0.6040088 , 0.58347592, 0.57907602, 0.6096309 ,\n",
       "        0.59374236, 0.57809826, 0.61329748, 0.59740895, 0.58372036,\n",
       "        0.6128086 , 0.60009778, 0.58347592, 0.60889758, 0.62454168,\n",
       "        0.62600831, 0.60889758, 0.62454168, 0.62600831, 0.60889758,\n",
       "        0.62649719, 0.6284527 , 0.60889758, 0.62478612, 0.6284527 ,\n",
       "        0.60889758, 0.62478612, 0.6284527 , 0.60889758, 0.62478612,\n",
       "        0.6284527 , 0.60938646, 0.62625275, 0.62820826, 0.60938646,\n",
       "        0.62625275, 0.62820826, 0.60938646, 0.62625275, 0.62820826,\n",
       "        0.63578587, 0.61989734, 0.60351992, 0.63358592, 0.62111953,\n",
       "        0.60718651, 0.63260816, 0.61891958, 0.61476412, 0.63431924,\n",
       "        0.62258616, 0.61036421, 0.63358592, 0.6196529 , 0.60987534,\n",
       "        0.6340748 , 0.62796382, 0.61231973, 0.63358592, 0.62894158,\n",
       "        0.61769738, 0.63358592, 0.62503055, 0.61769738, 0.63358592,\n",
       "        0.62503055, 0.61769738, 0.61427524, 0.5983867 , 0.58934246,\n",
       "        0.62307504, 0.60351992, 0.59032022, 0.61720851, 0.60498656,\n",
       "        0.58103153, 0.61085309, 0.59740895, 0.58689807, 0.61696407,\n",
       "        0.59887558, 0.58860914, 0.61891958, 0.60303104, 0.58909802,\n",
       "        0.62185285, 0.60547543, 0.60156441, 0.62478612, 0.60816426,\n",
       "        0.59105353, 0.62771938, 0.61183085, 0.60156441, 0.595209  ,\n",
       "        0.58494256, 0.58445368, 0.58787582, 0.5839648 , 0.58176485,\n",
       "        0.60547543, 0.58909802, 0.58200929, 0.59936446, 0.58665363,\n",
       "        0.585187  , 0.60034221, 0.59447568, 0.58592031, 0.60327548,\n",
       "        0.59080909, 0.58738695, 0.61329748, 0.59936446, 0.57907602,\n",
       "        0.61207529, 0.5996089 , 0.57980934, 0.61158641, 0.59447568,\n",
       "        0.58127597]),\n",
       " 'split3_test_accuracy': array([0.60498656, 0.61891958, 0.61329748, 0.60498656, 0.61891958,\n",
       "        0.61329748, 0.60498656, 0.61500856, 0.61329748, 0.60498656,\n",
       "        0.61696407, 0.61109753, 0.60498656, 0.61696407, 0.61109753,\n",
       "        0.60498656, 0.61696407, 0.61109753, 0.60498656, 0.61549743,\n",
       "        0.6128086 , 0.60498656, 0.61549743, 0.6128086 , 0.60498656,\n",
       "        0.61549743, 0.6128086 , 0.62454168, 0.6096309 , 0.60254217,\n",
       "        0.62356392, 0.61109753, 0.60596431, 0.62307504, 0.60474212,\n",
       "        0.60351992, 0.62111953, 0.60767538, 0.60303104, 0.62111953,\n",
       "        0.60791982, 0.60303104, 0.62038621, 0.60914202, 0.6027866 ,\n",
       "        0.62771938, 0.61476412, 0.61354192, 0.62771938, 0.61476412,\n",
       "        0.61354192, 0.62771938, 0.61476412, 0.61354192, 0.59887558,\n",
       "        0.59007578, 0.59129797, 0.60156441, 0.59545343, 0.58909802,\n",
       "        0.60083109, 0.59667563, 0.59154241, 0.60865314, 0.59789782,\n",
       "        0.5895869 , 0.6128086 , 0.60303104, 0.59789782, 0.6040088 ,\n",
       "        0.60009778, 0.5996089 , 0.61623075, 0.60425324, 0.59643119,\n",
       "        0.61305304, 0.61329748, 0.5983867 , 0.61451968, 0.60180885,\n",
       "        0.60254217, 0.5883647 , 0.59105353, 0.58420924, 0.59374236,\n",
       "        0.585187  , 0.58225373, 0.59472012, 0.58812026, 0.59569787,\n",
       "        0.59300904, 0.58860914, 0.58714251, 0.59423124, 0.58860914,\n",
       "        0.58592031, 0.58909802, 0.58176485, 0.58812026, 0.6040088 ,\n",
       "        0.595209  , 0.58347592, 0.60767538, 0.59545343, 0.58592031,\n",
       "        0.60131997, 0.59154241, 0.58640919, 0.60498656, 0.61891958,\n",
       "        0.61329748, 0.60498656, 0.61891958, 0.61329748, 0.60498656,\n",
       "        0.61500856, 0.61329748, 0.60498656, 0.61696407, 0.61109753,\n",
       "        0.60498656, 0.61696407, 0.61109753, 0.60498656, 0.61696407,\n",
       "        0.61109753, 0.60498656, 0.61549743, 0.6128086 , 0.60498656,\n",
       "        0.61549743, 0.6128086 , 0.60498656, 0.61549743, 0.6128086 ,\n",
       "        0.61745295, 0.61183085, 0.5996089 , 0.62576387, 0.60571987,\n",
       "        0.60009778, 0.6228306 , 0.61378636, 0.60303104, 0.62111953,\n",
       "        0.60791982, 0.60254217, 0.62038621, 0.60914202, 0.6027866 ,\n",
       "        0.62038621, 0.60767538, 0.6027866 , 0.62771938, 0.61476412,\n",
       "        0.61354192, 0.62771938, 0.61476412, 0.61354192, 0.62771938,\n",
       "        0.61476412, 0.61354192, 0.60303104, 0.59740895, 0.59618675,\n",
       "        0.59594231, 0.59765339, 0.595209  , 0.60303104, 0.60058665,\n",
       "        0.59203129, 0.60767538, 0.59912002, 0.59545343, 0.60425324,\n",
       "        0.59472012, 0.59325348, 0.61085309, 0.60425324, 0.59080909,\n",
       "        0.61354192, 0.60865314, 0.59374236, 0.6128086 , 0.6128086 ,\n",
       "        0.59985334, 0.61231973, 0.6040088 , 0.59985334, 0.59105353,\n",
       "        0.59349792, 0.58152041, 0.58934246, 0.58934246, 0.58469812,\n",
       "        0.59692007, 0.59007578, 0.58885358, 0.58738695, 0.5939868 ,\n",
       "        0.58665363, 0.59252017, 0.59203129, 0.585187  , 0.59227573,\n",
       "        0.58054265, 0.58616475, 0.60449768, 0.59692007, 0.58616475,\n",
       "        0.60791982, 0.595209  , 0.58347592, 0.60767538, 0.59618675,\n",
       "        0.58274261]),\n",
       " 'split4_test_accuracy': array([0.6340748 , 0.64067465, 0.63456368, 0.6340748 , 0.64067465,\n",
       "        0.63456368, 0.6340748 , 0.64067465, 0.63089709, 0.6340748 ,\n",
       "        0.63578587, 0.63187485, 0.6340748 , 0.63578587, 0.63187485,\n",
       "        0.6340748 , 0.63578587, 0.63187485, 0.6340748 , 0.63945246,\n",
       "        0.63554143, 0.6340748 , 0.63945246, 0.63554143, 0.6340748 ,\n",
       "        0.63945246, 0.63554143, 0.63383036, 0.62185285, 0.60938646,\n",
       "        0.63456368, 0.62331948, 0.6184307 , 0.63187485, 0.62820826,\n",
       "        0.6196529 , 0.63383036, 0.62111953, 0.61574187, 0.63383036,\n",
       "        0.62185285, 0.60865314, 0.63383036, 0.62136397, 0.61574187,\n",
       "        0.63236373, 0.62943046, 0.62307504, 0.63236373, 0.62943046,\n",
       "        0.62307504, 0.63236373, 0.62943046, 0.62307504, 0.61720851,\n",
       "        0.60645319, 0.60498656, 0.61818626, 0.60107553, 0.59936446,\n",
       "        0.6140308 , 0.60571987, 0.60229773, 0.61598631, 0.60791982,\n",
       "        0.59912002, 0.61500856, 0.60523099, 0.6027866 , 0.62014177,\n",
       "        0.60571987, 0.60645319, 0.61671963, 0.61305304, 0.59985334,\n",
       "        0.61769738, 0.61207529, 0.60645319, 0.61036421, 0.61256417,\n",
       "        0.61109753, 0.60009778, 0.59447568, 0.59814226, 0.60571987,\n",
       "        0.59814226, 0.59325348, 0.60596431, 0.59472012, 0.59300904,\n",
       "        0.60498656, 0.59789782, 0.59105353, 0.60327548, 0.59178685,\n",
       "        0.59154241, 0.59692007, 0.59300904, 0.59056465, 0.60620875,\n",
       "        0.59692007, 0.58812026, 0.60571987, 0.60351992, 0.59496456,\n",
       "        0.60596431, 0.60205329, 0.59203129, 0.6340748 , 0.64067465,\n",
       "        0.63456368, 0.6340748 , 0.64067465, 0.63456368, 0.6340748 ,\n",
       "        0.64067465, 0.63089709, 0.6340748 , 0.63578587, 0.63187485,\n",
       "        0.6340748 , 0.63578587, 0.63187485, 0.6340748 , 0.63578587,\n",
       "        0.63187485, 0.6340748 , 0.63945246, 0.63554143, 0.6340748 ,\n",
       "        0.63945246, 0.63554143, 0.6340748 , 0.63945246, 0.63554143,\n",
       "        0.63383036, 0.61769738, 0.61109753, 0.63358592, 0.6228306 ,\n",
       "        0.60987534, 0.63187485, 0.62771938, 0.61623075, 0.63383036,\n",
       "        0.62185285, 0.61549743, 0.63383036, 0.62136397, 0.60865314,\n",
       "        0.63383036, 0.62136397, 0.60865314, 0.63236373, 0.62943046,\n",
       "        0.62307504, 0.63236373, 0.62943046, 0.62307504, 0.63236373,\n",
       "        0.62943046, 0.62307504, 0.61574187, 0.59912002, 0.59814226,\n",
       "        0.61671963, 0.60327548, 0.59740895, 0.61060865, 0.60107553,\n",
       "        0.59814226, 0.61818626, 0.60645319, 0.59472012, 0.62111953,\n",
       "        0.6040088 , 0.59667563, 0.61696407, 0.60327548, 0.59912002,\n",
       "        0.62160841, 0.60180885, 0.59789782, 0.61867514, 0.60596431,\n",
       "        0.60449768, 0.61476412, 0.60914202, 0.60620875, 0.60327548,\n",
       "        0.59129797, 0.59423124, 0.59936446, 0.58909802, 0.59227573,\n",
       "        0.60596431, 0.59594231, 0.59325348, 0.6027866 , 0.59252017,\n",
       "        0.58494256, 0.6040088 , 0.59863114, 0.59716451, 0.60058665,\n",
       "        0.5939868 , 0.59300904, 0.60987534, 0.59716451, 0.59716451,\n",
       "        0.60889758, 0.59154241, 0.59545343, 0.60718651, 0.59716451,\n",
       "        0.59545343]),\n",
       " 'mean_test_accuracy': array([0.61473427, 0.62451116, 0.62358207, 0.61473427, 0.62451116,\n",
       "        0.62358207, 0.61473427, 0.62426672, 0.62265322, 0.61473427,\n",
       "        0.62392444, 0.62226217, 0.61473427, 0.62392444, 0.62226217,\n",
       "        0.61473427, 0.62392444, 0.62226217, 0.61483206, 0.62402237,\n",
       "        0.62314226, 0.61483206, 0.62402237, 0.62314226, 0.61483206,\n",
       "        0.62402237, 0.62314226, 0.62842178, 0.6164444 , 0.60779185,\n",
       "        0.62851961, 0.61615142, 0.6084765 , 0.62680854, 0.61732462,\n",
       "        0.61184932, 0.6275907 , 0.61707993, 0.6107736 , 0.62837292,\n",
       "        0.61776434, 0.60876942, 0.62685738, 0.61664013, 0.61072471,\n",
       "        0.62861739, 0.62089338, 0.61683597, 0.62861739, 0.62196846,\n",
       "        0.61610283, 0.62905728, 0.62235956, 0.6169826 , 0.61087157,\n",
       "        0.59503295, 0.59351747, 0.6117026 , 0.59288217, 0.591122  ,\n",
       "        0.61175173, 0.59874828, 0.59190416, 0.61624902, 0.60031223,\n",
       "        0.59156191, 0.61370696, 0.60041019, 0.59322448, 0.61522223,\n",
       "        0.59913928, 0.59728177, 0.61693359, 0.60725412, 0.59689037,\n",
       "        0.61869341, 0.60964973, 0.59630413, 0.61585802, 0.60735198,\n",
       "        0.59850389, 0.59268666, 0.58989994, 0.58828658, 0.59434837,\n",
       "        0.58711338, 0.58388695, 0.59889493, 0.58589174, 0.58853119,\n",
       "        0.59953029, 0.58848205, 0.58520668, 0.59889501, 0.58994842,\n",
       "        0.58696639, 0.59786811, 0.58867743, 0.5862332 , 0.60588547,\n",
       "        0.59327316, 0.58413114, 0.60744993, 0.59596163, 0.58784647,\n",
       "        0.6058367 , 0.59498413, 0.58784657, 0.61473427, 0.62451116,\n",
       "        0.62358207, 0.61473427, 0.62451116, 0.62358207, 0.61473427,\n",
       "        0.62426672, 0.62265322, 0.61473427, 0.62392444, 0.62226217,\n",
       "        0.61473427, 0.62392444, 0.62226217, 0.61473427, 0.62392444,\n",
       "        0.62226217, 0.61483206, 0.62402237, 0.62314226, 0.61483206,\n",
       "        0.62402237, 0.62314226, 0.61483206, 0.62402237, 0.62314226,\n",
       "        0.62690643, 0.61659127, 0.60583637, 0.6276397 , 0.61522247,\n",
       "        0.60544545, 0.6270041 , 0.61796021, 0.61111619, 0.62793289,\n",
       "        0.61820433, 0.61106692, 0.62768845, 0.61766658, 0.60955148,\n",
       "        0.62778622, 0.61815546, 0.61033361, 0.62905728, 0.62089338,\n",
       "        0.61683597, 0.62861739, 0.6214797 , 0.61610283, 0.62861739,\n",
       "        0.62011118, 0.61610283, 0.61160468, 0.59747689, 0.59209977,\n",
       "        0.6118003 , 0.59933464, 0.5905845 , 0.61013835, 0.60011697,\n",
       "        0.58760233, 0.61341338, 0.60065453, 0.59082851, 0.61531998,\n",
       "        0.60065419, 0.59273501, 0.61424473, 0.60236546, 0.59102427,\n",
       "        0.61796014, 0.60544534, 0.59649949, 0.61717807, 0.60769409,\n",
       "        0.59698845, 0.61761796, 0.60647214, 0.59821071, 0.59444624,\n",
       "        0.58735798, 0.58535346, 0.59121975, 0.58584232, 0.58691775,\n",
       "        0.59781959, 0.58809099, 0.58686898, 0.597428  , 0.59053518,\n",
       "        0.58481577, 0.60060558, 0.5939083 , 0.58799304, 0.59767274,\n",
       "        0.58897078, 0.5884333 , 0.60749848, 0.59346876, 0.58638008,\n",
       "        0.60730329, 0.59469063, 0.58789527, 0.60857418, 0.59508175,\n",
       "        0.58657542]),\n",
       " 'std_test_accuracy': array([0.01021454, 0.00891553, 0.00810838, 0.01021454, 0.00891553,\n",
       "        0.00810838, 0.01021454, 0.00944073, 0.0080967 , 0.01021454,\n",
       "        0.00704583, 0.00866054, 0.01021454, 0.00704583, 0.00866054,\n",
       "        0.01021454, 0.00704583, 0.00866054, 0.01018461, 0.00866279,\n",
       "        0.0086386 , 0.01018461, 0.00866279, 0.0086386 , 0.01018461,\n",
       "        0.00866279, 0.0086386 , 0.00600028, 0.00957318, 0.00693652,\n",
       "        0.00813479, 0.00789598, 0.00879808, 0.0066026 , 0.00919446,\n",
       "        0.00920328, 0.00701245, 0.0098216 , 0.00922152, 0.00746553,\n",
       "        0.01020877, 0.00696233, 0.00673268, 0.00862702, 0.00964721,\n",
       "        0.00557083, 0.00935475, 0.00477457, 0.00557083, 0.01060675,\n",
       "        0.00446801, 0.00584021, 0.01074756, 0.00488663, 0.00911082,\n",
       "        0.00804938, 0.00885242, 0.01015123, 0.00851624, 0.00814243,\n",
       "        0.00826874, 0.0063851 , 0.00995619, 0.00869513, 0.01035225,\n",
       "        0.00808294, 0.00780154, 0.00865995, 0.00809466, 0.00992394,\n",
       "        0.00794046, 0.00799025, 0.00544682, 0.00829898, 0.00786078,\n",
       "        0.00752402, 0.00570365, 0.0068581 , 0.00759145, 0.00719352,\n",
       "        0.01025672, 0.00671787, 0.00664348, 0.00925711, 0.01013092,\n",
       "        0.00962195, 0.00818442, 0.00768702, 0.00692079, 0.00858334,\n",
       "        0.00939631, 0.0097309 , 0.01014089, 0.00476756, 0.00998675,\n",
       "        0.01181673, 0.00712191, 0.00832931, 0.00921997, 0.00536492,\n",
       "        0.00531037, 0.00831461, 0.00507271, 0.0093825 , 0.00912766,\n",
       "        0.00522784, 0.007636  , 0.00682823, 0.01021454, 0.00891553,\n",
       "        0.00810838, 0.01021454, 0.00891553, 0.00810838, 0.01021454,\n",
       "        0.00944073, 0.0080967 , 0.01021454, 0.00704583, 0.00866054,\n",
       "        0.01021454, 0.00704583, 0.00866054, 0.01021454, 0.00704583,\n",
       "        0.00866054, 0.01018461, 0.00866279, 0.0086386 , 0.01018461,\n",
       "        0.00866279, 0.0086386 , 0.01018461, 0.00866279, 0.0086386 ,\n",
       "        0.00764867, 0.0061865 , 0.00722171, 0.00683054, 0.00938522,\n",
       "        0.00618563, 0.00634473, 0.00780688, 0.00659737, 0.00706341,\n",
       "        0.00883441, 0.00920382, 0.0070131 , 0.00816006, 0.00803806,\n",
       "        0.00720011, 0.01062035, 0.00877459, 0.00584021, 0.00935475,\n",
       "        0.00477457, 0.00557083, 0.01002904, 0.00446801, 0.00557083,\n",
       "        0.00879591, 0.00446801, 0.00983177, 0.0089167 , 0.00801821,\n",
       "        0.01227796, 0.00938889, 0.00769381, 0.00779183, 0.00717577,\n",
       "        0.00946519, 0.00965531, 0.00791448, 0.00973901, 0.00984482,\n",
       "        0.01050261, 0.00846715, 0.00814912, 0.00896348, 0.00780919,\n",
       "        0.00653763, 0.00665538, 0.00596293, 0.00654592, 0.00778374,\n",
       "        0.00619191, 0.00731901, 0.0064753 , 0.00772084, 0.00827905,\n",
       "        0.00712506, 0.00872427, 0.00765656, 0.00802148, 0.00701224,\n",
       "        0.00927249, 0.01132447, 0.00738175, 0.00891761, 0.00868003,\n",
       "        0.00623916, 0.00751413, 0.00897426, 0.01142967, 0.00635044,\n",
       "        0.00930251, 0.00614723, 0.00929839, 0.00811212, 0.00903897,\n",
       "        0.00563955, 0.00664233, 0.00929401, 0.00462712, 0.00590959,\n",
       "        0.00959004]),\n",
       " 'rank_test_accuracy': array([ 94,  19,  37,  94,  19,  37,  94,  23,  47,  94,  31,  50,  94,\n",
       "         31,  50,  94,  31,  50,  88,  25,  41,  88,  25,  41,  88,  25,\n",
       "         41,   8,  78, 126,   7,  80, 125,  18,  69, 109,  14,  71, 117,\n",
       "          9,  66, 123,  17,  76, 118,   3,  58,  74,   3,  56,  81,   1,\n",
       "         49,  72, 116, 166, 172, 112, 176, 183, 111, 151, 180,  79, 144,\n",
       "        181, 107, 143, 175,  87, 148, 159,  73, 132, 161,  61, 121, 163,\n",
       "         84, 130, 152, 178, 189, 195, 170, 203, 216, 150, 210, 192, 146,\n",
       "        193, 213, 149, 188, 204, 154, 191, 209, 134, 174, 215, 129, 164,\n",
       "        200, 135, 167, 199,  94,  19,  37,  94,  19,  37,  94,  23,  47,\n",
       "         94,  31,  50,  94,  31,  50,  94,  31,  50,  88,  25,  41,  88,\n",
       "         25,  41,  88,  25,  41,  16,  77, 136,  13,  86, 137,  15,  64,\n",
       "        114,  10,  62, 115,  12,  67, 122,  11,  63, 119,   1,  58,  74,\n",
       "          3,  57,  81,   3,  60,  81, 113, 157, 179, 110, 147, 186, 120,\n",
       "        145, 201, 108, 140, 185,  85, 141, 177, 106, 139, 184,  65, 138,\n",
       "        162,  70, 127, 160,  68, 133, 153, 169, 202, 212, 182, 211, 205,\n",
       "        155, 196, 206, 158, 187, 214, 142, 171, 197, 156, 190, 194, 128,\n",
       "        173, 208, 131, 168, 198, 124, 165, 207])}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GB.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c3111-861f-4bb2-9225-b3b1c3217ae6",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1ca0f59-3b45-415b-9221-6e8366e22a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e18fcd-a260-4ff2-8990-e5aed4749e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa8a3e-3df8-430b-a99f-1a744c322332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2a5fd-2fbf-498b-aae7-7a5a9ea4dc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
